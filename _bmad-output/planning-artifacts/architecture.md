---
stepsCompleted: [1, 2, 3, 4, 5, 6, 7, 8]
lastStep: 8
status: 'complete'
completedAt: '2026-02-14'
inputDocuments:
  - _bmad-output/planning-artifacts/product-brief-qa-localization-tool-2026-02-11.md
  - _bmad-output/planning-artifacts/prd.md
  - _bmad-output/planning-artifacts/prd-self-healing-translation.md
  - _bmad-output/planning-artifacts/prd-validation-report.md
  - _bmad-output/planning-artifacts/prd-original-pre-self-healing-2026-02-12.md
  - _bmad-output/planning-artifacts/ux-design-specification/index.md (14 files sharded)
  - _bmad-output/planning-artifacts/research/ai-llm-translation-qa-research-2025.md
  - _bmad-output/planning-artifacts/research/deployment-queue-infrastructure-research-2026-02-11.md
  - _bmad-output/planning-artifacts/research/technical-ai-llm-self-healing-translation-research-2026-02-14.md
  - _bmad-output/planning-artifacts/research/technical-qa-localization-tools-and-frameworks-research-2026-02-11/index.md (30 files sharded)
  - _bmad-output/planning-artifacts/research/technical-rule-engine-3-layer-pipeline-research-2026-02-12/index.md (10 files sharded)
  - docs/qa-localization-tool-plan.md
  - docs/QA _ Quality Cosmetic.md
workflowType: 'architecture'
project_name: 'qa-localization-tool'
user_name: 'Mona'
date: '2026-02-14'
---

# Architecture Decision Document

_This document defines all architectural decisions, implementation patterns, and project structure for the QA Localization Tool._

**Document Conventions:** Each architectural decision follows a consistent format: **Decision** (what), **Rationale** (why), and **Affects** (scope of impact). Refinements from Party Mode reviews are tracked as R-numbered items (e.g., R1, R2).

## Project Context Analysis

### Requirements Overview

**Functional Requirements:**

The project encompasses **80 FRs** (68 MVP + 12 Growth) across 10 categories plus **18 FR-SH** (Self-healing Translation, Growth phase):

| Category | FR Range | Architectural Implication |
|----------|----------|--------------------------|
| File Parsing & Segment Extraction | FR1‚ÄìFR9 | Requires SDLXLIFF/XLIFF parser (fast-xml-parser) with namespace handling. Supports streaming for large files and Excel bilingual input. |
| Dual Taxonomy & Rule Engine | FR10‚ÄìFR16 | 3-Layer QA Pipeline (Rule ‚Üí AI Screening ‚Üí Deep AI), MQM + Custom taxonomy, configurable severity weights |
| AI/LLM Integration | FR17‚ÄìFR22 | Vercel AI SDK v6, multi-provider abstraction, context injection across layers, fallback chain with version pinning |
| Scoring & Metrics | FR23‚ÄìFR30 | MQM formula `Score = max(0, 100 - NPT)` where NPT per 1,000 words, severity weights Critical=25/Major=5/Minor=1, score lifecycle state machine (FR70) |
| Review Workflow | FR31‚ÄìFR40 | 8 finding states, 7 review actions, auto-pass logic (‚â•95 + 0 Critical + L2 clean), recommended-pass ‚Üí true auto-pass progression |
| Glossary & Terminology | FR41‚ÄìFR45, FR72 | Multi-token glossary matching, case-sensitive/insensitive modes, glossary import/export |
| Language Bridge & Context | FR33, FR46‚ÄìFR50 | Back-translation display, source/target alignment, collapsible sidebar panel |
| Reporting & Export | FR51‚ÄìFR60 | PDF/Excel export, per-project and cross-project dashboards, trend analysis |
| Audit Trail & Immutability | FR61‚ÄìFR69 | Append-only audit log from Day 1, application-level immutability, override creates new entry |
| Score Lifecycle & Auto-pass | FR70‚ÄìFR72 | State machine for score progression, auto-pass rationale display, multi-token glossary |
| Self-healing Translation | FR-SH1‚ÄìFR-SH18 | Fix Agent + Judge Agent, RAG pipeline (pgvector), Progressive Trust (Shadow ‚Üí Assisted ‚Üí Autonomous), 4-layer fix pipeline |

**Non-Functional Requirements:**

**42 NFRs** + **7 NFR-SH** driving architectural decisions:

| NFR Category | Key Requirements | Architecture Impact |
|-------------|-----------------|---------------------|
| Performance | P95 < 2s rule layer, P95 < 8s AI layer, < 30s full pipeline per 100 segments | Async processing, queue-based AI calls, caching strategy |
| Scalability | 100K words/project, 50 concurrent users, 10 projects/tenant | Multi-tenant isolation, connection pooling, horizontal scaling readiness |
| Security | RBAC (Admin/QA Reviewer/Native Reviewer MVP), RLS policies, immutable audit | Row-Level Security on all tables, tenant_id from Day 1, append-only patterns |
| Reliability | 99.5% uptime, AI fallback chain, graceful degradation | Multi-provider fallback, circuit breaker pattern, offline-capable rule layer |
| Accessibility | WCAG 2.1 AA, keyboard-first navigation | Semantic HTML, ARIA labels, focus management, screen reader support |
| Cost | Economy mode ~$0.40/100K words, Thorough ~$2.40/100K words | Tiered processing (L1+L2 vs L1+L2+L3), token budget management |

**Scale & Complexity:**

- Primary domain: **Full-stack Web Application**
- Complexity level: **High** ‚Äî domain-specific QA pipeline, multi-layer AI integration, real-time processing, multi-tenancy
- Estimated architectural components: **~15‚Äì20 major components** (parser, rule engine, AI orchestrator, scoring engine, review workflow, audit system, auth/RBAC, file storage, queue, realtime, glossary, reporting, export, dashboard, self-healing pipeline)

### Technical Constraints & Dependencies

**Technology Stack (from PRD & Research):**

| Layer | Technology | Rationale |
|-------|-----------|-----------|
| Framework | Next.js (App Router) | RSC for performance, API routes for backend, Vercel deployment |
| UI | shadcn/ui + Tailwind CSS | 16 base + 14 custom components, Indigo primary (#4F46E5), Inter font |
| Backend/DB | Supabase (Auth + PostgreSQL + Storage + Realtime) | Multi-tenant RLS, pgvector for RAG, real-time subscriptions |
| ORM | Drizzle ORM | Type-safe queries, migration management |
| Queue | Inngest | Durable functions, retry logic, fan-out for AI pipeline |
| AI SDK | Vercel AI SDK v6 | Multi-provider abstraction, streaming, structured output |
| File Parsing | fast-xml-parser | SDLXLIFF/XLIFF parsing with namespace support |
| CJK/Thai | Intl.Segmenter API | Word boundary detection for non-space-delimited languages |

**Key Constraints:**

1. **Single-Pass Completion** ‚Äî 5 pillars: zero re-upload, inline editing, persistent state, keyboard-first, batch operations
2. **Multi-tenancy from Day 1** ‚Äî tenant_id on all tables, RLS policies written but not enforced in MVP
3. **Immutable Audit Trail from Day 1** ‚Äî append-only, no edits/deletes on audit records
4. **Economy mode vs Thorough mode** ‚Äî user-selectable processing depth affects cost and latency
5. **SDLXLIFF as Primary Format** ‚Äî Trados ecosystem, XLIFF 1.2 uses same parser (SDLXLIFF is superset)
6. **3-Layer Pipeline Architecture** ‚Äî each layer must be independently testable and bypassable
7. **Progressive Trust for Self-healing** ‚Äî Shadow ‚Üí Assisted ‚Üí Autonomous with kill criteria

### Cross-Cutting Concerns Identified

1. **Multi-tenancy Isolation** ‚Äî tenant_id permeates every table, query, and API call; RLS enforcement strategy needed
2. **Audit Trail Consistency** ‚Äî every state change across all modules must produce append-only audit entries
3. **AI Cost Management** ‚Äî token budgets, provider fallback costs, Economy mode vs Thorough mode routing
4. **Error Handling & Fallback** ‚Äî AI provider failures, parser errors, queue failures all need graceful degradation
5. **CJK/Thai Language Handling** ‚Äî word segmentation, character counting, and confidence calibration affect parser, rule engine, and AI layers
6. **Real-time State Synchronization** ‚Äî review progress, score updates, and finding state changes must propagate via Supabase Realtime
7. **File Processing Pipeline** ‚Äî upload ‚Üí parse ‚Üí extract segments ‚Üí queue for QA ‚Üí aggregate results; must handle large files without memory issues
8. **RBAC Enforcement** ‚Äî role-based access control must be consistently applied across UI, API, and database layers
9. **Score Calculation Atomicity** ‚Äî MQM scoring across 3 layers with recalculation must prevent race conditions (FR70 handoff)
10. **Configuration Management** ‚Äî per-tenant and per-project settings for taxonomy weights, AI thresholds, auto-pass criteria, glossaries

### Architecture Handoff Items (from PRD Validation)

These 8 items were explicitly flagged for resolution in this Architecture Document:

| # | Item | Source | Decision Needed |
|---|------|--------|-----------------|
| 1 | FR18/FR69 priority: version pinning vs fallback availability | PRD Validation Round 3 | Define priority order when pinned version unavailable |
| 2 | FR70 score recalculation atomicity | PRD Validation Round 3 | Prevent race conditions between pipeline layers |
| 3 | FR72 substring fallback logging | PRD Validation Round 3 | Log as "degraded matching mode" for audit trail |
| 4 | RLS enforcement strategy | PRD Validation Round 3 | Write-but-not-enforce (MVP) vs enforce from Day 1 |
| 5 | Immutable audit log DB mechanism | PRD Validation Round 3 | Triggers vs write-only RLS vs separate table |
| 6 | SDLXLIFF parser memory strategy | PRD Validation Round 3 | DOM vs streaming for large files |
| 7 | Uptime monitoring tool selection | PRD Validation Round 3 | Tool selection for 99.5% SLA tracking |
| 8 | AI fallback chaos testing approach | PRD Validation Round 3 | Testing strategy for multi-provider failover |

## Starter Template Evaluation

### Primary Technology Domain

**Full-stack Web Application** ‚Äî Next.js 16 App Router with Supabase backend, based on project requirements for real-time QA processing, multi-tenant data isolation, and rich interactive review UI.

### Technology Versions (Verified February 2026)

| Technology | Version | Key Changes |
|-----------|---------|-------------|
| Next.js | 16.1.6 LTS | Turbopack default, React Compiler stable, async APIs mandatory |
| shadcn/ui | CLI-based | `npx shadcn@latest init`, unified Radix UI package, RTL support |
| @supabase/supabase-js | 2.95.3 | SSR via `@supabase/ssr`, cookie-based auth |
| Drizzle ORM | 0.45.1 (stable) | v1.0 beta available; use stable for production |
| Inngest | 3.52.0 | App Router support, Vercel Fluid Compute streaming |
| Vercel AI SDK | 6.0.86 | Agent abstraction, human-in-the-loop, structured output |
| Tailwind CSS | 4.1.18 | Zero-config, CSS `@theme` directive, no tailwind.config.js |
| TypeScript | 5.9.x | 6.0 Beta announced but not stable; use 5.9.x |
| fast-xml-parser | 5.3.5 | ESM support, no C/C++ dependencies |

### Starter Options Considered

| Option | Description | Pros | Cons |
|--------|------------|------|------|
| `create-next-app -e with-supabase` | Official Supabase template | Cookie auth ready, Tailwind + TS | Missing Drizzle, Inngest, AI SDK, shadcn/ui |
| Nextbase Starter | Community Next.js + Supabase starter | Includes Jest + Playwright | Community-maintained, may be outdated |
| supa-next-starter | Community Next.js + Supabase + shadcn | Includes shadcn setup | Missing Drizzle, Inngest, AI SDK |
| **`create-next-app` + Manual Setup** | Official Next.js CLI + layered dependencies | Full version control, latest everything | Requires manual dependency setup |

### Selected Starter: `create-next-app` + Manual Setup

**Rationale for Selection:**

1. No existing starter template combines all required technologies (Next.js 16 + Supabase + Drizzle + shadcn/ui + Inngest + AI SDK v6)
2. Full control over dependency versions ensures latest stable releases
3. Avoids dependency on community starters with uncertain maintenance
4. AI-assisted project setup makes manual configuration fast and reliable

**Initialization Command:**

```bash
# 1. Create Next.js app (Next.js 16 + Tailwind v4 + TypeScript + App Router)
npx create-next-app@latest qa-localization-tool --typescript --tailwind --eslint --app --src-dir

# 2. Initialize shadcn/ui
npx shadcn@latest init

# 3. Install core dependencies
npm i @supabase/supabase-js @supabase/ssr drizzle-orm inngest ai fast-xml-parser

# 4. Install dev dependencies
npm i -D drizzle-kit @types/node
```

**Architectural Decisions Provided by Starter:**

**Language & Runtime:**
TypeScript 5.9.x on Node.js 20.9+, strict mode enabled, path aliases via `@/`

**Styling Solution:**
Tailwind CSS v4 with CSS `@theme` directive (no tailwind.config.js), shadcn/ui components with full source ownership

**Build Tooling:**
Turbopack (default in Next.js 16) for development, React Compiler for automatic memoization, filesystem caching for faster restarts

**Code Organization:**
Next.js App Router with `src/app/` directory structure, React Server Components by default, `"use client"` directive for interactive components

**Development Experience:**
Fast Refresh via Turbopack, TypeScript strict mode, ESLint integration, filesystem caching for incremental builds

> **Note:** Project initialization using this command sequence should be the first implementation story.

## Core Architectural Decisions

### Decision Priority Analysis

**Critical Decisions (Block Implementation):**
- Data schema design pattern (Drizzle-first + SQL for RLS)
- RBAC implementation (Hybrid JWT + DB with M3 read/write split)
- 3-Layer Pipeline orchestration (3-tier Inngest pattern)
- Score recalculation atomicity (Event-driven via Inngest serial queue)
- Immutable audit log mechanism (App-level + Write-only RLS + DB trigger)
- RLS enforcement strategy (Enforce critical tables from Day 1)

**Important Decisions (Shape Architecture):**
- API patterns (Server Actions + Route Handlers hybrid)
- State management (Zustand domain stores)
- RSC/Client component boundaries (Feature-based)
- CI/CD pipeline (GitHub Actions quality gate + Vercel deploy)
- Monitoring stack (Vercel Analytics + Better Stack)

**Deferred Decisions (Post-MVP):**
- Redis caching (upgrade from Next.js cache if performance gate fails)
- Better Stack Logs (upgrade from Vercel Logs for long retention)
- Storybook (optional for design system components)

---

### Category 1: Data Architecture

#### 1.1 Schema Design Pattern

- **Decision:** Drizzle Schema-first + SQL migrations for RLS
- **Rationale:** TypeScript schemas as single source of truth (version controlled, type-safe), RLS policies + triggers as custom SQL migrations (also version controlled)
- **Affects:** All data models, migrations, RLS policies

**Folder Structure:**
```
src/db/
  schema/        ‚Üê Drizzle TS schemas
  migrations/    ‚Üê drizzle-kit generated + custom SQL (RLS, triggers)
```

#### 1.2 Data Validation Strategy

- **Decision:** Drizzle-Zod + custom Zod extensions
- **Rationale:** `drizzle-zod` generates base schemas from DB ‚Üí extend with custom Zod for form/API validation
- **Constraint:** Flow must be unidirectional: `drizzle schema ‚Üí drizzle-zod ‚Üí extend` (no circular dependencies)
- **Affects:** All API inputs, form validation, DB inserts

#### 1.3 Caching Strategy

- **Decision:** Next.js built-in caching + Supabase connection pooling (MVP) ‚Üí Upstash Redis if needed (Growth)
- **Rationale:** MVP doesn't need shared cross-instance cache; Supabase Supavisor handles DB connections
- **Escape Hatch:** If performance gate fails (P95 > 2s rule layer), upgrade to Redis

**Rule Layer Hot Data Caching:**

| Data | Cache Strategy | TTL | Invalidation |
|------|---------------|-----|-------------|
| Glossary terms | `unstable_cache` + tag `glossary-{projectId}` | 5 min | `revalidateTag` on glossary mutation |
| Taxonomy config | `unstable_cache` + tag `taxonomy-{projectId}` | 10 min | `revalidateTag` on config change |
| Language rules | In-memory static module | ‚àû | Redeploy only |

**Pipeline Design:** Load cached data once per project run, reuse across all segments (not per-segment queries)

**Performance Gate:** Benchmark test must pass P95 < 2s (cold cache) before MVP ship

#### 1.4 Immutable Audit Log Mechanism (Handoff #5)

- **Decision:** Application-level audit entries + Write-only RLS + DB trigger (defense-in-depth)
- **Rationale:** Application code controls audit entry format and content (FR66 "application-level immutability"). Write-only RLS prevents accidental DELETE/UPDATE from the application. The DB trigger prevents DELETE/UPDATE even from the SQL Editor or admin console.
- **Affects:** audit_logs table, all state-changing operations
- **Constraint:** `service_role` key must be server-side only (Inngest functions + seed scripts)

**Defense-in-Depth Layers:**
1. Application code: only INSERT, never UPDATE/DELETE audit entries
2. RLS policy: INSERT only (blocks app-level DELETE/UPDATE)
3. DB trigger: RAISE EXCEPTION on DELETE/UPDATE (blocks admin-level)

**Index Strategy (must be defined at schema creation):**
- Composite index: `(tenant_id, created_at)`
- Composite index: `(entity_type, entity_id)`
- Consider monthly table partitioning for long-term scalability

#### 1.5 RLS Enforcement Strategy (Handoff #4)

- **Decision:** Enforce RLS on critical tables from Day 1, defer reference tables
- **Rationale:** Stronger than PRD minimum ("write but not enforce") ‚Äî critical tenant data must be isolated from Day 1

**Table Classification:**

| Enforce RLS (MVP) | No RLS Needed (MVP) |
|---|---|
| projects, files, segments, findings, scores, audit_logs, glossaries, review_sessions | taxonomy_definitions, severity_configs (shared reference data) |

**Mandatory Test Suite (CI Gate):**
- Cross-tenant leak tests: Tenant A must NOT see Tenant B data
- Negative tests with different JWT claims (tenant_id)
- RLS tests must pass before every merge

**Helper Pattern:** Use the `withTenant(query, tenantId)` Drizzle helper for consistent tenant filtering.

#### 1.6 SDLXLIFF Parser Memory Strategy (Handoff #6)

- **Decision:** DOM parsing (full parse) with 30MB file size guard
- **Rationale:** SDLXLIFF files typically range from 5-15MB (about 100K words). The DOM approach simplifies segment extraction and namespace handling. A 30MB file-size guard protects against Vercel's 1024MB serverless memory limit: a 30MB XML file incurs roughly 4x parse overhead (120MB), leaving adequate headroom.
- **Affects:** File upload endpoint, parser module

#### 1.7 Migration Strategy

- **Decision:** Drizzle Kit generate + migrate (SQL files in version control)
- **Rationale:** Reproducible migrations, version controlled, auditable
- **Command:** `drizzle-kit generate` ‚Üí SQL files ‚Üí `drizzle-kit migrate` to apply

---

### Category 2: Authentication & Security

#### 2.1 RBAC Implementation Pattern

- **Decision:** Hybrid JWT claims + DB table with M3 read/write split
- **Rationale:** Fast reads from JWT for UI/RLS, accurate writes from DB lookup for security-critical operations

**M3 Pattern (Read/Write Split):**

| Operation Type | Trust Source | Rationale |
|---------------|-------------|-----------|
| Read (view data, UI guards) | JWT `app_metadata` claims | Fast, no DB query |
| Write (mutations, approve, delete) | `user_roles` DB table query | Accurate, no sync gap |

**Role Sync:** The `user_roles` table serves as the source of truth. The Supabase Admin API writes updated claims to `app_metadata`. The client-side Realtime subscription detects the change and refreshes the JWT.

**Security Test Scenarios (CI Gate):**

| # | Attack Scenario | Expected Behavior |
|---|----------------|-------------------|
| S1 | Admin removes user role ‚Üí user has old JWT ‚Üí attempts write | BLOCKED by DB lookup (M3) |
| S2 | User tampers JWT claims | BLOCKED by Supabase signature verification |
| S3 | Tenant A admin assigns role in Tenant B | BLOCKED by user_roles RLS (tenant_id) |
| S4 | Rate limit bypass via multiple tokens | BLOCKED by rate limiting per user_id |

#### 2.2 API Security Middleware Pattern

- **Decision:** Edge Middleware (auth check) + Server-side helper (role check)
- **Rationale:** Defense-in-depth ‚Äî the Edge layer catches unauthenticated requests early, while the server layer handles fine-grained RBAC

**Flow:**
```
Edge Middleware (runs at Edge Runtime):
  1. Read session cookie ‚Üí verify JWT valid
  2. Extract tenant_id from JWT
  3. No session ‚Üí redirect /login
  4. Tenant mismatch ‚Üí 403
  5. Pass through to server

Server Helper (requireRole):
  1. Read JWT claims ‚Üí check role (reads)
  2. Write operations ‚Üí query user_roles DB (M3)
  3. Insufficient role ‚Üí throw 403
```

**Rate Limiting:** Edge middleware includes rate limiting per user_id (Vercel built-in or simple in-memory counter for MVP)

#### 2.3 AI Version Pinning vs Fallback (Handoff #1)

- **Decision:** Pinned version first ‚Üí fallback with audit flag
- **Rationale:** Don't block processing, but always audit which version was actually used
- **Priority Order:** `pinned version ‚Üí latest same provider ‚Üí next provider (all flagged in audit)`
- **Admin Notification:** Alert when pinned version becomes unavailable

**Chaos Testing (Handoff #8):** Weekly scheduled CI run + manual trigger before releases ‚Äî mock provider failure ‚Üí verify fallback chain + audit log entries (R31)

---

### Category 3: API & Communication Patterns

#### 3.1 API Pattern

- **Decision:** Server Actions for UI mutations + Route Handlers for external integrations
- **Rationale:** Best of both ‚Äî type-safe UI mutations with Server Actions, proper endpoints for webhooks/external APIs

**Boundary Rules:**

| Use Server Actions | Use Route Handlers |
|---|---|
| UI form submissions | Inngest serve endpoint (`/api/inngest`) |
| Review actions (accept/reject) | Supabase auth webhooks |
| Glossary CRUD | File upload with progress |
| Score override | Health check endpoint (`/api/health`) |
| Project settings | External API integrations (future) |

**Organization:** Server Actions co-located in feature folders (`src/features/{feature}/actions/`)

#### 3.2 Error Handling Standard

- **Decision:** Hybrid ‚Äî structured returns for Server Actions + Error Boundaries for unexpected errors
- **Rationale:** Predictable UI error handling + safe catch-all for unexpected failures

**Standardized Return Type:**
```typescript
type ActionResult<T> =
  | { success: true; data: T }
  | { success: false; error: string; code: string }
```

All Server Actions must return this type ‚Äî no exceptions.

**Audit trail errors must never silently fail** ‚Üí throw + alert

#### 3.3 AI Pipeline Orchestration (Inngest)

- **Decision:** 3-tier pattern: Orchestrator ‚Üí Batch Workers ‚Üí Per-segment layer pipeline
- **Rationale:** Parallel segment processing + sequential layer execution + layer-level retry + Inngest concurrency limit compliance

**Pipeline Flow:**
```
1. Orchestrator:
   a. Read project config (Economy/Thorough mode)
   b. Group segments by language pair (FR13 counter accuracy)
   c. Batch segments (20/batch for concurrency limits)
   d. Fan-out batches via step.invoke()

2. Batch Worker (per batch):
   a. Per segment: L1 (rules) ‚Üí L2 (AI screening) ‚Üí L3 (deep AI, if Thorough)
   b. Each layer = separate step.run() with deterministic ID
   c. Layer-level retry on failure (R13 idempotency)

3. Aggregation:
   a. Per language pair: calculate finding counters (FR13)
   b. All pairs: calculate final MQM score (atomic operation)
   c. Emit score.calculated event ‚Üí Supabase Realtime push
```

**Idempotency:** Every Inngest step must have deterministic ID: `step.run("segment-{id}-L{layer}", ...)`

**Economy vs Thorough:** Orchestrator reads project config ‚Üí Thorough mode includes L3 batches, Economy skips

#### 3.4 Score Recalculation Atomicity (Handoff #2)

- **Decision:** Event-driven recalculation via Inngest serial queue
- **Rationale:** Finding change emits event ‚Üí Inngest processes serially per project (no race conditions) ‚Üí Supabase Realtime pushes updated score

**Implementation:**
```typescript
inngest.createFunction(
  {
    id: "recalculate-score",
    concurrency: { key: "event.data.projectId", limit: 1 }
  },
  { event: "finding.changed" },
  async ({ step }) => { /* recalculate MQM score */ }
)
```

**Client-side debounce:** 500ms debounce on finding changes to reduce event volume during rapid reviewer edits

**UX:** Score shows "recalculating..." ‚Üí Realtime subscription pushes updated score (~1-2s delay, acceptable)

#### 3.5 AI Model Selection per Pipeline Layer

- **Decision:** Layer-specific model assignment with fallback chain
- **Rationale:** Research (AI/LLM Translation QA Research) confirms multi-model strategy is optimal ‚Äî cheap models for screening, premium models for deep analysis. CJK+Thai quality varies significantly across providers.
- **Source:** Research comparison matrix (Section 1.5) ‚Äî Claude Sonnet 9/10 Thai, GPT-4o 8/10, Gemini Flash 7/10

**Model Assignment:**

| Layer | Primary Model | Rationale | Fallback |
|-------|--------------|-----------|----------|
| L1 (Rules) | No LLM | Pure rule-based, zero cost | ‚Äî |
| L2 (AI Screening) | GPT-4o-mini | Cheapest ($0.15/1M input), structured output 9/10, sufficient for screening | Gemini 2.0 Flash ($0.10/1M) |
| L3 (Deep AI) | Claude Sonnet | Best semantic (10/10), Thai (9/10), tone/register (10/10), cultural (9/10) | GPT-4o ($2.50/1M, 9/10 CJK) |

**Cost Estimates per 100K Words (from Research):**

| Mode | L2 Cost | L3 Cost | Total |
|------|---------|---------|-------|
| Economy (L1+L2) | ~$0.40 | ‚Äî | ~$0.40 |
| Thorough (L1+L2+L3) | ~$0.40 | ~$2.00 | ~$2.40 |

**Provider Configuration (in `src/lib/ai/providers.ts`):**
```typescript
export const LAYER_MODELS = {
  L2: {
    primary: { provider: 'openai', model: 'gpt-4o-mini' },
    fallback: { provider: 'google', model: 'gemini-2.0-flash' },
  },
  L3: {
    primary: { provider: 'anthropic', model: 'claude-sonnet-4-5-20250929' },
    fallback: { provider: 'openai', model: 'gpt-4o' },
  },
} as const
```

**Version Pinning (per Decision 2.3):** Each model entry includes pinned version. Fallback triggers audit flag per existing pattern.

**CJK+Thai Considerations:**
- Claude Sonnet excels at Thai nuance and register detection ‚Äî must be L3 primary
- GPT-4o-mini adequate for L2 screening (catching obvious errors), not subtle cultural issues
- Gemini Flash has largest context window (1M tokens) but weakest Thai (7/10) ‚Äî L2 fallback only

#### 3.6 Language-Pair Configuration

- **Decision:** Per-language-pair configuration table for thresholds and AI behavior
- **Rationale:** Research (Self-healing & AI/LLM QA) emphasizes CJK+Thai require different confidence thresholds and calibration than European languages. One-size-fits-all thresholds fail for nuanced languages.
- **Source:** Research recommendation #5 "Start with English‚ÜíCJK+Thai and calibrate confidence thresholds per pair"

**Schema Design:**
```typescript
// src/db/schema/languagePairConfig.ts
export const languagePairConfigs = pgTable('language_pair_configs', {
  id: uuid('id').primaryKey().defaultRandom(),
  tenantId: uuid('tenant_id').notNull(),
  sourceLang: varchar('source_lang', { length: 10 }).notNull(),  // e.g., 'en'
  targetLang: varchar('target_lang', { length: 10 }).notNull(),  // e.g., 'th'
  autoPassThreshold: integer('auto_pass_threshold').default(95),  // MQM score threshold
  l2ConfidenceMin: integer('l2_confidence_min').default(70),      // min confidence to skip L3
  l3ConfidenceMin: integer('l3_confidence_min').default(80),      // min confidence for auto-accept
  mutedCategories: jsonb('muted_categories').default([]),          // MQM categories to suppress
  wordSegmenter: varchar('word_segmenter', { length: 20 }).default('intl'), // 'intl' | 'space'
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow(),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow(),
})
```

**Default Configurations:**

| Language Pair | Auto-pass | L2 Confidence Min | Word Segmenter | Notes |
|--------------|-----------|-------------------|----------------|-------|
| EN ‚Üí TH | 93 | 75 | `intl` (Intl.Segmenter) | Thai has no spaces; lower auto-pass due to complexity |
| EN ‚Üí JA | 93 | 75 | `intl` | Japanese mixed scripts need careful handling |
| EN ‚Üí KO | 94 | 72 | `intl` | Korean spacing rules differ from English |
| EN ‚Üí ZH-CN | 94 | 72 | `intl` | Simplified Chinese |
| EN ‚Üí * (default) | 95 | 70 | `space` | European/Latin languages |

**MVP Scope:** Ship with hardcoded defaults per table above. Admin UI for editing = Growth phase.

#### 3.7 Neural QE Validation Layer (COMET-QE / xCOMET)

- **Decision:** MVP uses LLM-only evaluation (GEMBA approach). Growth phase adds COMET-QE/xCOMET as secondary neural validation layer.
- **Rationale:** Research confirms "Combination of LLM evaluation + neural metrics gives best results" (AI/LLM QA Research ¬ß2.3). However, COMET/xCOMET are Python libraries (Unbabel/COMET) ‚Äî adding Python runtime to a Node.js/Vercel stack in MVP adds unnecessary infrastructure complexity. Growth phase has budget for a sidecar service.
- **Source:** Research ¬ß2.3 MT Evaluation Metrics ‚Äî xCOMET ~75% F1 on MQM error detection, COMET-QE is best reference-free metric

**Why This Matters:**

| Metric | What It Does | MVP Gap It Fills |
|--------|-------------|-----------------|
| **COMET-QE** | Reference-free quality score (0-1) per segment | Cross-validates LLM confidence ‚Äî catches cases where LLM is confident but wrong |
| **xCOMET** | Error spans + severity, MQM-compatible | Provides independent MQM annotations to compare against L2/L3 findings |

**Research Recommended Architecture (Tier 1.5):**
```
L1 (Rules) ‚Üí L1.5 (COMET-QE fast score) ‚Üí L2 (AI Screening) ‚Üí L3 (Deep AI)
                    ‚Üë
        If COMET-QE score > 0.85 ‚Üí skip L2 (high quality, no AI needed)
        If COMET-QE score < 0.40 ‚Üí flag for L3 directly (poor quality, skip L2)
```

The COMET-QE scoring layer acts as a smart router, saving AI costs by skipping L2 for clearly good or clearly bad segments.

**Growth Implementation Plan:**

| Option | Pros | Cons | Recommendation |
|--------|------|------|:-------------:|
| **A: Python microservice on Railway/Fly.io** | Full COMET/xCOMET access, GPU support | Separate service to maintain, cold starts | ‚≠ê Recommended |
| B: Supabase Edge Function (Deno) | Same infra, no new service | COMET not available in Deno, limited | ‚ùå Not feasible |
| C: ONNX-exported model in Node.js | No Python needed | Quality loss from export, large model | ‚ùå Too complex |

**Recommended Growth Architecture (Option A):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Python Microservice (Railway)    ‚îÇ
‚îÇ - FastAPI + Unbabel/COMET        ‚îÇ
‚îÇ - POST /score  (COMET-QE)       ‚îÇ
‚îÇ - POST /annotate (xCOMET spans) ‚îÇ
‚îÇ - GPU: T4 (Railway, ~$0.50/hr)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Next.js App (Vercel)             ‚îÇ
‚îÇ - Inngest step calls microservice‚îÇ
‚îÇ - Results stored in findings     ‚îÇ
‚îÇ - Used for confidence calibration‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Integration with Existing Pipeline:**
```typescript
// Growth: Add as Inngest step in batch worker (after L1, before L2)
await step.run(`segment-${id}-comet-qe`, async () => {
  const cometScore = await fetch(COMET_SERVICE_URL + '/score', {
    method: 'POST',
    body: JSON.stringify({ source, target, sourceLang, targetLang }),
  }).then(r => r.json())

  // Smart routing based on COMET-QE score
  if (cometScore.score > 0.85) return { skipL2: true, reason: 'comet-high' }
  if (cometScore.score < 0.40) return { skipToL3: true, reason: 'comet-low' }
  return { continueL2: true, cometScore: cometScore.score }
})
```

**MVP Preparation (zero cost):**
- `feedback_events` table already captures AI model + confidence ‚Üí use to benchmark COMET-QE accuracy later
- `language_pair_configs` table includes `l2ConfidenceMin` ‚Üí extend with `cometQeThresholdHigh` / `cometQeThresholdLow` in Growth
- Log AI evaluation scores in structured format ‚Üí enables direct comparison with COMET-QE when added

**Cost Impact (Growth):**

| Component | Per 100K Words | Notes |
|-----------|:--------------:|-------|
| COMET-QE scoring | ~$0.05 | Fast inference, GPU batch processing |
| xCOMET annotation | ~$0.15 | Heavier model, span-level output |
| **AI cost savings** | -$0.10 to -$0.30 | Smart routing skips L2 for clear segments |
| **Net impact** | ~$0.00 to -$0.10 | Roughly cost-neutral or slight savings |

---

### Category 4: Frontend Architecture

#### 4.1 State Management

- **Decision:** Zustand with domain-split stores
- **Rationale:** Lightweight (1KB), RSC-friendly (no Provider), simple API, sufficient for UI state when combined with Supabase Realtime for server state

**Store Boundaries:**

| Store | Responsibility | Example State |
|-------|---------------|--------------|
| `useReviewStore` | Review panel UI | activeSegmentId, filterState, selectedFindings |
| `usePipelineStore` | Pipeline progress | processingStatus, layerProgress, errors |
| `useUIStore` | Global UI | sidebarOpen, theme, activePanel |
| `useKeyboardStore` | Keyboard shortcuts (cross-feature) | shortcutsEnabled, activeContext, registered shortcuts |

**Rule:** 1 store per feature domain ‚Äî no God Store

**Realtime Integration Pattern (unidirectional flow):**
```
Supabase Realtime ‚Üí Zustand Store update ‚Üí UI re-render
```

Custom hooks combine Zustand + Realtime subscriptions (e.g., `useRealtimeFindings`)

#### 4.2 RSC/Client Component Boundary Strategy

- **Decision:** Feature-based boundaries ‚Äî Server Component wrapper for data, Client Component for interaction
- **Rationale:** Balance RSC benefits (small bundle, fast load) with rich interactivity where needed

**Boundary Map:**

| Feature | Default | Rationale |
|---------|---------|-----------|
| Review panel | üî¥ Client | Keyboard shortcuts, inline editing, 8 finding states, real-time |
| Dashboard | üü¢ Server + üî¥ Client charts | Data-heavy layout server-rendered, chart components client |
| Project list/detail | üü¢ Server | Data display, minimal interactivity |
| Settings/Config | üü¢ Server + üî¥ Client forms | Layout server, forms client |
| Glossary editor | üî¥ Client | Dynamic fields, real-time validation |

**Pattern:** Server Component fetches data ‚Üí passes as props to Client Component entry point

**Loading UX:** Wrap every RSC boundary in `<Suspense fallback>` with a skeleton matching compact density (0.75x).

#### 4.3 Component Organization

- **Decision:** Feature-based co-location + shared components
- **Rationale:** Developers work within one folder per feature; shared UI components in centralized location

**Project Structure:**
```
src/
  components/                    ‚Üê shared/global
    ui/                          ‚Üê shadcn base (16 components)
    layout/                      ‚Üê app shell, sidebar, header
  features/
    review/
      components/                ‚Üê ReviewPanel, FindingCard, SegmentViewer
      actions/                   ‚Üê Server Actions for review
      hooks/                     ‚Üê useReviewState, useKeyboardShortcuts
      stores/                    ‚Üê review.store.ts
    dashboard/
      components/                ‚Üê ScoreChart, TrendGraph
    pipeline/
      components/                ‚Üê PipelineStatus, ProgressIndicator
    glossary/
      components/                ‚Üê GlossaryEditor, TermList
  styles/
    tokens.css                   ‚Üê CSS custom properties (@theme for Tailwind v4)
    animations.css               ‚Üê shared transition/animation definitions
  lib/                           ‚Üê shared utilities (mqm-calculator, etc.)
  db/
    schema/                      ‚Üê Drizzle TS schemas
    migrations/                  ‚Üê SQL migrations
```

**Naming Convention:**

| Type | Pattern | Example |
|------|---------|---------|
| shadcn base | `src/components/ui/{name}.tsx` | `ui/button.tsx` |
| App layout | `src/components/layout/{name}.tsx` | `layout/app-sidebar.tsx` |
| Feature component | `src/features/{feature}/components/{Name}.tsx` | `review/components/FindingCard.tsx` |
| Feature hook | `src/features/{feature}/hooks/use{Name}.ts` | `review/hooks/useKeyboardShortcuts.ts` |
| Feature store | `src/features/{feature}/stores/{name}.store.ts` | `review/stores/review.store.ts` |
| Feature action | `src/features/{feature}/actions/{name}.action.ts` | `review/actions/updateFinding.action.ts` |
| Shared util | `src/lib/{name}.ts` | `lib/mqm-calculator.ts` |
| DB schema | `src/db/schema/{name}.ts` | `db/schema/findings.ts` |

#### 4.4 Form Handling

- **Decision:** Native HTML forms for simple cases + React Hook Form for complex cases + direct action calls for keyboard shortcuts
- **Rationale:** Match tool to complexity ‚Äî don't over-engineer simple forms with RHF

| Form Type | Approach |
|-----------|----------|
| Page forms (login, project create, settings) | Native `<form>` + `useActionState` + Zod validation at Server Action |
| Inline editing (finding card, segment edit) | React Hook Form + Zod |
| Complex forms (glossary editor, taxonomy config) | React Hook Form + Zod + field arrays |
| Keyboard-driven actions (accept/reject via shortcut) | Direct Server Action call via Zustand (not a form) |

---

### Category 5: Infrastructure & Deployment

#### 5.1 CI/CD Pipeline

- **Decision:** GitHub Actions (quality gate) + Vercel Git Integration (deploy)
- **Rationale:** GH Actions for automated quality checks, Vercel for deploy + preview URLs

**CI Pipeline:**
```yaml
# quality-gate (every PR)
jobs:
  quality:
    steps:
      - lint (ESLint + Prettier)
      - type-check (tsc --noEmit)
      - unit-test (Vitest)
      - rls-test (Supabase local CLI)
      - build (next build ‚Äî catches RSC boundary errors)

# e2e-gate (merge to main only)
jobs:
  e2e:
    steps:
      - playwright (4 critical path tests)

# chaos-test (weekly scheduled + manual trigger)
jobs:
  chaos:
    steps:
      - ai-fallback-chaos (mock provider failure ‚Üí verify fallback + audit)
```

**Supabase in CI:** `supabase/setup-cli@v1` ‚Üí `supabase start` ‚Üí run RLS tests against local instance (never production)

**Critical Path E2E Tests:**

| # | Test | Coverage |
|---|------|----------|
| E1 | Upload SDLXLIFF ‚Üí see segments | File parsing pipeline |
| E2 | Run QA ‚Üí see findings + score | Full 3-layer pipeline |
| E3 | Accept/reject finding ‚Üí score recalculate | Review workflow + atomicity |
| E4 | Login ‚Üí see only own tenant data | Auth + multi-tenancy |

#### 5.2 Uptime Monitoring (Handoff #7)

- **Decision:** Vercel Analytics (performance) + Better Stack (uptime + status page)
- **Rationale:** Free tiers sufficient for MVP; 99.5% uptime = ‚â§ 3.65 hrs downtime/month ‚Üí must detect within 3-5 minutes

**Better Stack Monitors (5 free):**

| # | Monitor | Check |
|---|---------|-------|
| 1 | Homepage | `GET /` |
| 2 | API Health | `GET /api/health` (DB + Auth + Inngest) |
| 3 | Inngest Endpoint | `POST /api/inngest` health |
| 4 | Supabase | Project URL |
| 5 | (Reserved for Growth) | ‚Äî |

**Health Endpoint:** `/api/health` checks DB connection + Supabase Auth + Inngest reachability. Must include `Cache-Control: no-store` header.

**Alert Escalation:**

| Level | Condition | Channel |
|-------|-----------|---------|
| ‚ö†Ô∏è Warning | Down > 3 min (1 fail) | Slack |
| üî¥ Critical | Down > 9 min (3 consecutive fails) | Slack + Email + SMS |
| ‚úÖ Recovery | Back up | Slack |

#### 5.3 Environment Configuration

- **Decision:** Vercel Environment Variables + `.env.local` + `vercel env pull`
- **Rationale:** Secrets in Vercel Dashboard only (never in repo), `vercel env pull` for local sync

**`.env.example` (committed to repo):**
```bash
NEXT_PUBLIC_SUPABASE_URL=       # Supabase project URL
NEXT_PUBLIC_SUPABASE_ANON_KEY=  # Supabase anon/public key (client-safe)
SUPABASE_SERVICE_ROLE_KEY=      # Server-only: Supabase service role
INNGEST_EVENT_KEY=              # Inngest event key
INNGEST_SIGNING_KEY=            # Inngest webhook signing
OPENAI_API_KEY=                 # Primary AI provider
ANTHROPIC_API_KEY=              # Fallback AI provider
```

**Convention:** `NEXT_PUBLIC_` prefix = exposed to client browser; no prefix = server-only

#### 5.4 Logging Strategy

- **Decision:** pino structured JSON logging (Node.js runtime) ‚Üí Vercel Logs (MVP) ‚Üí Better Stack Logs (Growth)
- **Rationale:** Structured logging from Day 1 avoids format refactoring later; Vercel Logs free for MVP

**Runtime Constraint:** pino for Server Components + Route Handlers + Inngest functions (Node.js). Edge Middleware uses `console.log` (Edge Runtime incompatibility).

**AI Layer Log Fields (mandatory):**
```json
{
  "level": "info",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "layer": "L2",
  "tokens_in": 1200,
  "tokens_out": 350,
  "estimated_cost_usd": 0.0023,
  "duration_ms": 1850,
  "segment_id": "seg-123",
  "project_id": "proj-456"
}
```

Token count + estimated cost per request enables Economy vs Thorough cost tracking per PRD requirements.

#### 5.5 Substring Fallback Logging (Handoff #3)

- **Decision:** Both audit log entry + structured pino log
- **Rationale:** The audit entry creates a compliance trail ‚Äî when glossary matching operates in degraded mode, it affects score reliability. The structured log enables monitoring and alerting if degraded mode frequency exceeds the threshold.

---

### Decision Impact Analysis

**Implementation Sequence:**
1. Project initialization (starter template + dependencies)
2. DB schema + Drizzle config + RLS policies + audit trigger
3. Supabase Auth + RBAC (JWT claims + user_roles table)
4. Edge middleware + server-side auth helpers
5. Feature folder structure + component organization + design tokens
6. Server Actions + Route Handlers + error handling standard
7. Inngest pipeline orchestration (3-tier pattern)
8. Zustand stores + Realtime integration
9. CI/CD pipeline (GH Actions + Vercel)
10. Monitoring + logging setup

**Cross-Component Dependencies:**

| Decision | Depends On | Blocks |
|----------|-----------|--------|
| RLS policies (1.5) | Schema design (1.1) | Auth middleware (2.2), RLS tests (5.1) |
| RBAC M3 pattern (2.1) | Schema (1.1), Auth (Supabase) | Middleware (2.2), Server Actions (3.1) |
| Pipeline orchestration (3.3) | Inngest setup, AI SDK, Schema | Score recalculation (3.4), Monitoring (5.2) |
| Feature structure (4.3) | Starter template (Step 3) | All frontend components, stores, actions |
| CI pipeline (5.1) | All test strategies (R4, R26) | Deployment safety |

### Handoff Items Resolution Summary

| # | Handoff Item | Resolved In | Decision |
|---|-------------|-------------|----------|
| 1 | FR18/FR69 version pinning vs fallback | Decision 2.3 | Pinned first ‚Üí fallback with audit flag |
| 2 | FR70 score recalculation atomicity | Decision 3.4 | Event-driven Inngest serial queue per project |
| 3 | FR72 substring fallback logging | Decision 5.5 | Both audit entry + structured log |
| 4 | RLS enforcement strategy | Decision 1.5 | Enforce critical tables from Day 1, defer reference |
| 5 | Immutable audit log mechanism | Decision 1.4 | App-level + Write-only RLS + DB trigger |
| 6 | SDLXLIFF parser memory strategy | Decision 1.6 | DOM with 30MB guard |
| 7 | Uptime monitoring tool | Decision 5.2 | Vercel Analytics + Better Stack |
| 8 | AI fallback chaos testing | Decision 5.1 (R31) | Weekly scheduled CI + manual trigger |

### Party Mode Refinements Log

| # | Refinement | Source | Category |
|---|-----------|--------|----------|
| R1 | Audit log composite indexes + monthly partitioning | Amelia (Dev) | Data |
| R2 | Audit log DB trigger DELETE/UPDATE block | Murat (Test) | Data |
| R3 | Parser limit 50MB ‚Üí 30MB (Vercel memory) | Amelia (Dev) | Data |
| R4 | RLS mandatory cross-tenant leak test suite in CI | Murat (Test) | Data |
| R5 | Rule layer hot data caching plan (unstable_cache + tags) | Mary (Analyst) | Data |
| R6 | RBAC M3 pattern: JWT reads, DB writes | Amelia (Dev) | Auth |
| R7 | Security test scenarios S1-S4 in test suite | Murat (Test) | Auth |
| R8 | Edge middleware rate limiting | Murat (Test) | Auth |
| R9 | AI fallback chaos test in CI | Murat (Test) | Auth |
| R10 | Server Actions in feature folders (revised from centralized) | Amelia (Dev) | API |
| R11 | Standardized ActionResult<T> return type | Amelia (Dev) | API |
| R12 | 3-tier Inngest pipeline (Orchestrator ‚Üí Batch ‚Üí Segment) | Amelia (Dev) | API |
| R13 | Deterministic Inngest step IDs for idempotency | Murat (Test) | API |
| R14 | Pipeline failure scenario test suite F1-F5 | Murat (Test) | API |
| R15 | Score recalculation client debounce 500ms | Murat (Test) | API |
| R16 | Pipeline orchestrator groups by language pair + reads mode config | Mary (Analyst) | API |
| R17 | Zustand domain stores + useKeyboardStore | Amelia + Sally | Frontend |
| R18 | Unidirectional Realtime ‚Üí Store ‚Üí UI flow | Amelia (Dev) | Frontend |
| R19 | Concrete RSC boundary map per feature | Amelia (Dev) | Frontend |
| R20 | Suspense fallback skeletons match compact density | Sally (UX) | Frontend |
| R21 | Standardized naming convention table | Amelia (Dev) | Frontend |
| R22 | Design tokens in src/styles/tokens.css + animations.css | Sally (UX) | Frontend |
| R23 | Keyboard-driven actions category (direct call, not form) | Sally (UX) | Frontend |
| R24 | Testing stack: Vitest + Testing Library + Playwright + ESLint RSC rule | Murat (Test) | Frontend |
| R25 | Supabase local CLI in GH Actions for RLS tests | Amelia (Dev) | Infra |
| R26 | Split quality-gate (every PR) + e2e-gate (main only) + 4 E2E tests | Murat (Test) | Infra |
| R27 | /api/health endpoint with Cache-Control: no-store | Amelia (Dev) | Infra |
| R28 | Better Stack 5 monitors + alert escalation config | Murat (Test) | Infra |
| R29 | pino Node.js only, console.log for Edge | Amelia (Dev) | Infra |
| R30 | AI layer must log token count + estimated cost | Mary (Analyst) | Infra |
| R31 | AI chaos test weekly scheduled (not every PR) | Mary (Analyst) | Infra |
| R32 | .env.example with all keys + descriptions | Amelia (Dev) | Infra |
| R33 | DB access: Drizzle only on server, Supabase client for Auth/Storage/Realtime | Amelia (Dev) | Patterns |
| R34 | Error pattern: try-catch in Server Actions, no try-catch in Inngest steps | Amelia (Dev) | Patterns |
| R35 | Env vars: centralized validated access via @/lib/env (Zod) | Amelia (Dev) | Patterns |
| R36 | Supabase client: 3 factories in src/lib/supabase/ (server, client, admin) | Amelia (Dev) | Patterns |
| R37 | TypeScript: strict + noUncheckedIndexedAccess + exactOptionalPropertyTypes | Amelia (Dev) | Patterns |
| R38 | Accessibility: mandatory aria-label, form labels, role/aria-live | Sally (UX) | Patterns |
| R39 | Responsive: Tailwind default breakpoints only, desktop-first | Sally (UX) | Patterns |
| R40 | Toast: sonner as sole notification library | Sally (UX) | Patterns |
| R41 | Test naming: describe/it with behavior description | Murat (Test) | Patterns |
| R42 | Test data: factory functions in src/test/factories.ts | Murat (Test) | Patterns |
| R43 | Test organization: co-located units, db/__tests__/rls/, e2e/, src/test/ | Murat (Test) | Patterns |
| R44 | Inngest client: src/lib/inngest/client.ts + function registry in features | Amelia (Dev) | Structure |
| R45 | Auth helpers: src/lib/auth/requireRole.ts + getCurrentUser.ts | Amelia (Dev) | Structure |
| R46 | DB connection: src/db/connection.ts separate from index | Amelia (Dev) | Structure |
| R47 | Feature-level validation folders in feature modules | Amelia (Dev) | Structure |
| R48 | Error boundaries: error.tsx in (app)/ + projects/[projectId]/ | Amelia (Dev) | Structure |
| R49 | 7 missing UX components + StatusBadge + ProgressRing + EmptyState (shared) | Sally (UX) | Structure |
| R50 | Mock organization: src/test/mocks/ with standardized mocks | Murat (Test) | Structure |
| R51 | Test fixtures: src/test/fixtures/ with segments, SDLXLIFF, glossary | Murat (Test) | Structure |
| R52 | Vitest workspace: separate unit (jsdom) and rls (node) projects | Murat (Test) | Structure |
| R53 | AI Model Selection per pipeline layer (L2: GPT-4o-mini, L3: Claude Sonnet) | Research Integration | API |
| R54 | Language-pair configuration table with per-language thresholds | Research Integration | Data |
| R55 | feedback_events table in MVP for Growth-phase ML training data | Research Integration | Data |
| R56 | Growth Architecture section: Self-healing pipeline, patterns, roadmap | Research Integration | Structure |
| R57 | COMET-QE/xCOMET neural QE validation layer (Decision 3.7, Growth) | Research Integration | API |

## Implementation Patterns & Consistency Rules

### Naming Patterns

#### Database Naming

| Element | Convention | Example |
|---------|-----------|---------|
| Tables | snake_case, plural | `projects`, `findings`, `audit_logs` |
| Columns | snake_case | `tenant_id`, `created_at`, `file_name` |
| Foreign keys | `{referenced_table_singular}_id` | `project_id`, `user_id` |
| Indexes | `idx_{table}_{columns}` | `idx_findings_tenant_created` |
| Enums | snake_case | `finding_status`, `severity_level` |
| Timestamps | `created_at`, `updated_at` | Always `timestamptz` (with timezone) |

#### API / Event Naming

| Element | Convention | Example |
|---------|-----------|---------|
| Route Handlers | `/api/{resource}` kebab-case | `/api/inngest`, `/api/health` |
| Server Action files | `{action}.action.ts` camelCase | `updateFinding.action.ts` |
| Server Action functions | camelCase verb-first | `updateFinding()`, `submitReview()` |
| Inngest events | `{domain}.{verb}` dot-notation | `finding.changed`, `pipeline.started` |
| Inngest function IDs | kebab-case | `recalculate-score`, `process-pipeline-batch` |

#### Code Naming

| Element | Convention | Example |
|---------|-----------|---------|
| Components | PascalCase | `FindingCard.tsx`, `ReviewPanel.tsx` |
| Hooks | `use` + PascalCase | `useReviewStore.ts`, `useKeyboardShortcuts.ts` |
| Stores | `{domain}.store.ts` | `review.store.ts`, `pipeline.store.ts` |
| Utilities | camelCase | `mqmCalculator.ts`, `segmentParser.ts` |
| Types/Interfaces | PascalCase, no `I` prefix | `Finding`, `ReviewSession`, `PipelineConfig` |
| Constants | UPPER_SNAKE_CASE | `MAX_FILE_SIZE_BYTES`, `DEFAULT_BATCH_SIZE` |
| Zod schemas | camelCase + `Schema` suffix | `findingSchema`, `projectConfigSchema` |
| CSS files | kebab-case | `tokens.css`, `animations.css` |

---

### Structure Patterns

#### Test Co-location

| Test Type | Location | Naming |
|-----------|----------|--------|
| Unit tests | Co-located next to source | `mqmCalculator.test.ts` |
| Component tests | Co-located next to component | `FindingCard.test.tsx` |
| RLS tests | `src/db/__tests__/rls/` | `findings.rls.test.ts` |
| E2E tests | `e2e/` (project root) | `review-workflow.spec.ts` |
| Inngest tests | Co-located | `recalculate-score.test.ts` |
| Test factories | `src/test/factories.ts` | Shared factory functions |
| Test setup | `src/test/setup.ts` | Global test configuration |

#### Import Organization (ESLint enforced)

```typescript
// 1. External packages
import { useState } from 'react'
import { create } from 'zustand'

// 2. Internal aliases (@/)
import { Button } from '@/components/ui/button'
import { useReviewStore } from '@/features/review/stores/review.store'

// 3. Relative imports (same feature)
import { FindingCard } from './FindingCard'
```

**Export Pattern:** Named exports only ‚Äî no default exports (except Next.js page/layout where required)

---

### Format Patterns

#### Server Action Response

All Server Actions must return the standardized `ActionResult<T>` type:

```typescript
type ActionResult<T> =
  | { success: true; data: T }
  | { success: false; error: string; code: string }
```

#### Route Handler Response

```typescript
// Success
NextResponse.json({ data: result }, { status: 200 })

// Error
NextResponse.json({ error: message, code: 'VALIDATION_ERROR' }, { status: 400 })
```

#### Data Formats

| Format | Convention |
|--------|-----------|
| Date/Time in DB | `timestamptz` (stored as UTC) |
| Date/Time in JSON | ISO 8601 `"2026-02-14T10:30:00.000Z"` |
| Date/Time in UI | `Intl.DateTimeFormat` per user locale |
| JSON field naming | camelCase (JavaScript convention) |
| DB column naming | snake_case (PostgreSQL convention) |
| Booleans | `true`/`false` (never 1/0) |

Drizzle handles camelCase ‚Üî snake_case mapping automatically.

---

### Communication Patterns

#### Inngest Event Structure

```typescript
interface InngestEvent {
  name: string               // "finding.changed"
  data: {
    tenantId: string         // always present
    projectId: string        // always present
    // ... event-specific fields
  }
  user?: { id: string }     // who triggered (if applicable)
}
```

#### Supabase Realtime Subscription

```typescript
// Every subscription must filter by project + cleanup on unmount
useEffect(() => {
  const channel = supabase
    .channel(`{table}:{projectId}`)
    .on('postgres_changes', {
      event: '*',
      schema: 'public',
      table: '{table}',
      filter: `project_id=eq.${projectId}`
    }, handler)
    .subscribe()

  return () => { supabase.removeChannel(channel) }
}, [projectId])
```

#### Zustand Store Template

```typescript
interface ReviewState {
  // State
  activeSegmentId: string | null
  findings: Finding[]

  // Actions (verb-first naming)
  setActiveSegment: (id: string) => void
  updateFinding: (finding: Finding) => void
  resetState: () => void
}

export const useReviewStore = create<ReviewState>()((set) => ({
  activeSegmentId: null,
  findings: [],
  setActiveSegment: (id) => set({ activeSegmentId: id }),
  updateFinding: (finding) => set((s) => ({
    findings: s.findings.map(f => f.id === finding.id ? finding : f)
  })),
  resetState: () => set({ activeSegmentId: null, findings: [] }),
}))
```

---

### Data Access Patterns

#### Server-Side DB Access: Drizzle Only

```typescript
// ‚úÖ Server-side: Drizzle ORM for all DB queries
const findings = await db
  .select()
  .from(findingsTable)
  .where(and(
    eq(findingsTable.projectId, projectId),
    eq(findingsTable.tenantId, tenantId)
  ))

// ‚ùå FORBIDDEN: raw SQL via Drizzle
await db.execute(sql`SELECT * FROM findings WHERE ...`)

// ‚ùå FORBIDDEN: Supabase client for DB queries on server
const { data } = await supabase.from('findings').select('*')
```

**Rule:** Supabase client is for Auth, Storage, and Realtime subscriptions only. All DB queries go through Drizzle ORM.

#### Supabase Client Instantiation

Three factory files ‚Äî always import from these:

| File | Use Case | Runtime |
|------|----------|---------|
| `src/lib/supabase/server.ts` | Server Components, Server Actions | Node.js |
| `src/lib/supabase/client.ts` | Client Components (Auth, Realtime) | Browser |
| `src/lib/supabase/admin.ts` | Admin operations (role sync, seed) | Node.js server-only |

Do not instantiate Supabase clients inline.

#### Environment Variable Access

```typescript
// src/lib/env.ts ‚Äî centralized, Zod-validated
import { z } from 'zod'

const envSchema = z.object({
  NEXT_PUBLIC_SUPABASE_URL: z.string().url(),
  NEXT_PUBLIC_SUPABASE_ANON_KEY: z.string(),
  SUPABASE_SERVICE_ROLE_KEY: z.string(),
  OPENAI_API_KEY: z.string(),
  ANTHROPIC_API_KEY: z.string(),
  INNGEST_EVENT_KEY: z.string(),
  INNGEST_SIGNING_KEY: z.string(),
})

export const env = envSchema.parse(process.env)
```

**Rule:** All env access through `@/lib/env` ‚Äî do not use `process.env` directly.

---

### Error Handling Patterns

| Context | Pattern |
|---------|---------|
| Server Action (expected) | Return `{ success: false, error, code }` via ActionResult |
| Server Action (unexpected) | Throw ‚Üí caught by Error Boundary |
| Inngest steps | No try-catch ‚Äî let Inngest handle retries |
| Audit-critical errors | Must never silently fail ‚Üí throw + pino.error |

#### Server Action Error Pattern

```typescript
export async function updateFinding(input: Input): Promise<ActionResult<Finding>> {
  try {
    const result = await db.update(...)
    await auditLog('finding.updated', { ... })  // never skip audit
    return { success: true, data: result }
  } catch (error) {
    logger.error({ error, input }, 'Failed to update finding')
    return { success: false, error: 'Failed to update finding', code: 'UPDATE_FAILED' }
  }
}
```

#### Inngest Step Error Pattern

```typescript
// Let step.run() handle retries ‚Äî no try-catch inside
const result = await step.run("process-L1-segment-42", async () => {
  return await processLayer1(segment)  // if fails, Inngest retries
})
```

---

### Loading State Patterns

| Context | Pattern |
|---------|---------|
| RSC page load | `loading.tsx` or `<Suspense fallback={<Skeleton />}>` |
| Server Action pending | `useActionState` ‚Üí `isPending` ‚Üí disable button + spinner |
| Pipeline progress | Supabase Realtime ‚Üí Zustand ‚Üí animated progress |
| Score recalculating | "Recalculating..." badge ‚Üí Realtime push |

Skeletons must match compact density (0.75x) to prevent layout shift.

---

### Accessibility Patterns

| Requirement | Implementation |
|------------|---------------|
| Interactive elements | Must be keyboard accessible (no tabindex > 0) |
| Images | Must have `alt` (or `alt=""` if decorative) |
| Form fields | Must have associated `<Label htmlFor>` |
| Loading states | `role="status" aria-live="polite"` |
| Error messages | `role="alert" aria-live="assertive"` |
| Color contrast | ‚â• 4.5:1 text, ‚â• 3:1 UI components |
| Focus order | Logical tab sequence |

---

### Responsive Patterns

Desktop-first approach (review tool = desktop primary):

| Breakpoint | Width | Usage |
|-----------|-------|-------|
| 2xl | 1536px+ | Ultra-wide layouts |
| xl | 1280px+ | Full desktop (primary) |
| lg | 1024px+ | Small laptop |
| md | 768px+ | Tablet |
| sm | 640px+ | Mobile (limited) |

**Rule:** Use Tailwind default breakpoints only ‚Äî no arbitrary `min-[1100px]:` values.

---

### Notification Pattern

Use `sonner` (shadcn/ui recommended) as sole toast/notification library:

```typescript
import { toast } from 'sonner'

toast.success('Finding accepted')
toast.error('Failed to update finding')
toast.promise(asyncAction(), {
  loading: 'Updating...',
  success: 'Updated',
  error: 'Failed',
})
```

No `alert()`, no custom modals, no inline messages for action feedback.

---

### Test Patterns

#### Test Naming Convention

```typescript
describe('MQMCalculator', () => {
  it('should return 100 when no penalties exist', () => { ... })
  it('should deduct 25 points per critical finding', () => { ... })
  it('should never return below 0', () => { ... })
})
```

Pattern: `describe("{Unit}")` ‚Üí `it("should {behavior} when {condition}")`

#### Test Data Factory

```typescript
// src/test/factories.ts
export function buildFinding(overrides?: Partial<Finding>): Finding {
  return {
    id: faker.string.uuid(),
    tenantId: 'test-tenant',
    projectId: 'test-project',
    segmentId: faker.string.uuid(),
    severity: 'major',
    category: 'accuracy',
    status: 'pending',
    createdAt: new Date().toISOString(),
    ...overrides,
  }
}
```

**Rule:** Test data via factory functions ‚Äî never hardcode test data inline.

#### TypeScript Strictness

```json
{
  "compilerOptions": {
    "strict": true,
    "noUncheckedIndexedAccess": true,
    "exactOptionalPropertyTypes": true
  }
}
```

---

### Anti-Patterns (Forbidden)

| # | Anti-Pattern | Correct Approach |
|---|-------------|-----------------|
| 1 | Default export (except page/layout) | Use named exports |
| 2 | `any` type | Define proper types/interfaces |
| 3 | Direct DB query without Drizzle | Use Drizzle ORM |
| 4 | `service_role` key in client code | Use `anon` key for client, restrict `service_role` to server-only |
| 5 | Hardcode tenant_id | Read from JWT/session |
| 6 | Mutate Zustand state directly | Use `set()` function |
| 7 | `"use client"` on page component | Use feature boundary pattern |
| 8 | Skip audit log for state change | Log every state change to audit |
| 9 | `console.log` in production | Use pino logger (Node.js) |
| 10 | Inline Tailwind colors | Use CSS custom properties from tokens.css |
| 11 | `process.env` direct access | Use `@/lib/env` validated config |
| 12 | Inline Supabase client creation | Use factory from `@/lib/supabase/` |
| 13 | try-catch inside Inngest step.run() | Let Inngest handle retries |
| 14 | Arbitrary responsive breakpoints | Use Tailwind defaults only |
| 15 | Hardcoded test data | Use factory functions from `src/test/factories.ts` |

### Enforcement

- **ESLint:** Import order, no default exports, no console.log, RSC boundary props check
- **TypeScript:** Strict mode + noUncheckedIndexedAccess catches type issues at compile time
- **CI Quality Gate:** lint ‚Üí type-check ‚Üí unit tests ‚Üí RLS tests ‚Üí build all pass before merge
- **Code Review:** AI agents must verify patterns before submitting changes

## Project Structure & Boundaries

### Complete Project Directory Structure

```
qa-localization-tool/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ quality-gate.yml              # Every PR: lint, type-check, test, rls-test, build
‚îÇ       ‚îú‚îÄ‚îÄ e2e-gate.yml                  # Merge to main: Playwright critical paths
‚îÇ       ‚îî‚îÄ‚îÄ chaos-test.yml                # Weekly: AI fallback chaos test
‚îú‚îÄ‚îÄ .env.example                          # All env keys with descriptions
‚îú‚îÄ‚îÄ .eslintrc.json
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .prettierrc
‚îú‚îÄ‚îÄ drizzle.config.ts                     # Drizzle Kit configuration
‚îú‚îÄ‚îÄ next.config.ts                        # Next.js 16 (Turbopack, React Compiler)
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ playwright.config.ts
‚îú‚îÄ‚îÄ tsconfig.json                         # strict + noUncheckedIndexedAccess
‚îú‚îÄ‚îÄ vitest.config.ts                      # Base Vitest config
‚îú‚îÄ‚îÄ vitest.workspace.ts                   # Separate unit (jsdom) + rls (node) projects
‚îÇ
‚îú‚îÄ‚îÄ e2e/                                  # Playwright E2E tests
‚îÇ   ‚îú‚îÄ‚îÄ review-workflow.spec.ts           # E1+E3
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.spec.ts                  # E2
‚îÇ   ‚îú‚îÄ‚îÄ multi-tenancy.spec.ts             # E4
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îÇ       ‚îî‚îÄ‚îÄ sample.sdlxliff
‚îÇ
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ fonts/                            # Inter, JetBrains Mono
‚îÇ
‚îú‚îÄ‚îÄ supabase/                             # Supabase local development
‚îÇ   ‚îú‚îÄ‚îÄ config.toml
‚îÇ   ‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001_initial_schema.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002_rls_policies.sql          # RLS for critical tables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 003_audit_trigger.sql         # DELETE/UPDATE block on audit_logs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 004_auth_hooks.sql            # Role sync webhook function
‚îÇ   ‚îî‚îÄ‚îÄ seed.sql
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ app/                              # Next.js App Router
    ‚îÇ   ‚îú‚îÄ‚îÄ globals.css                   # Tailwind v4 @theme imports
    ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                    # Root (fonts, metadata, Toaster/sonner)
    ‚îÇ   ‚îú‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îú‚îÄ‚îÄ error.tsx
    ‚îÇ   ‚îú‚îÄ‚îÄ not-found.tsx
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ (auth)/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/page.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signup/page.tsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callback/route.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ (app)/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                # App shell (sidebar, header)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ error.tsx                 # App-level error boundary (R48)
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx              # Project list (Server)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ new/page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [projectId]/
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ page.tsx          # Project detail (Server)
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ error.tsx         # Project-level error boundary (R48)
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ files/page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ settings/page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ glossary/page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ review/
    ‚îÇ   ‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ [sessionId]/page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ loading.tsx
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ page.tsx
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ users/page.tsx
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ settings/page.tsx
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ api/
    ‚îÇ       ‚îú‚îÄ‚îÄ inngest/route.ts          # Inngest serve (imports function registry)
    ‚îÇ       ‚îú‚îÄ‚îÄ health/route.ts           # DB + Auth + Inngest check, no-store
    ‚îÇ       ‚îî‚îÄ‚îÄ webhooks/
    ‚îÇ           ‚îî‚îÄ‚îÄ supabase/route.ts     # Auth webhook (role sync)
    ‚îÇ
    ‚îú‚îÄ‚îÄ components/                       # Shared/global components
    ‚îÇ   ‚îú‚îÄ‚îÄ ui/                           # shadcn/ui base (16+3 shared custom)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ button.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dialog.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dropdown-menu.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ badge.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ skeleton.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tooltip.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status-badge.tsx          # Finding status (8 states) ‚Äî shared (R49)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ progress-ring.tsx         # Circular progress ‚Äî shared (R49)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ empty-state.tsx           # Empty state with illustration + CTA (R49)
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ layout/
    ‚îÇ       ‚îú‚îÄ‚îÄ app-sidebar.tsx
    ‚îÇ       ‚îú‚îÄ‚îÄ app-header.tsx
    ‚îÇ       ‚îú‚îÄ‚îÄ page-header.tsx
    ‚îÇ       ‚îî‚îÄ‚îÄ compact-layout.tsx        # 0.75x density wrapper
    ‚îÇ
    ‚îú‚îÄ‚îÄ features/                         # Feature modules
    ‚îÇ   ‚îú‚îÄ‚îÄ review/                       # FR31-FR40
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReviewPanel.tsx                # "use client" entry
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReviewPanel.test.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SegmentViewer.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SegmentViewer.test.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FindingCard.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FindingCard.test.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FindingList.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FindingFilter.tsx              # Filter by severity/status/category (R49)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ScoringPanel.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReviewActions.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LanguageBridge.tsx              # FR33
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SegmentNavigator.tsx            # J/K nav UI indicator (R49)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BatchActions.tsx                # Bulk accept/reject toolbar (R49)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CommentThread.tsx               # Finding comments (R49)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SeveritySelector.tsx            # Severity picker (R49)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ updateFinding.action.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ updateFinding.action.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ submitReview.action.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ overrideScore.action.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useKeyboardShortcuts.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useKeyboardShortcuts.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useRealtimeFindings.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stores/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ review.store.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review.store.test.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation/                        # Feature-level form validation (R47)
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ findingSchema.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                     # FR10-FR22
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PipelineStatus.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PipelineConfig.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LayerProgress.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ startPipeline.action.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cancelPipeline.action.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inngest/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts                       # Function registry ‚Äî exports all (R44)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batchWorker.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batchWorker.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scoreRecalculator.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layers/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ruleLayer.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ruleLayer.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiScreeningLayer.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiScreeningLayer.test.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deepAiLayer.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deepAiLayer.test.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stores/
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ pipeline.store.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ parser/                       # FR1-FR9
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sdlxliffParser.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sdlxliffParser.test.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excelParser.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excelParser.test.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segmentExtractor.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segmentExtractor.test.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ namespaceHandler.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.ts              # MAX_FILE_SIZE_BYTES (30MB)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ scoring/                      # FR23-FR30, FR70
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ScoreDisplay.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AutoPassIndicator.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mqmCalculator.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mqmCalculator.test.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scoreLifecycle.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ glossary/                     # FR41-FR45, FR72
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GlossaryEditor.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GlossaryEditor.test.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TermList.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ importGlossary.action.ts
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ updateTerm.action.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multiTokenMatcher.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ multiTokenMatcher.test.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ taxonomy/                     # FR10-FR16
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TaxonomyConfig.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ updateTaxonomy.action.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ severityWeights.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/                    # FR51-FR60
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ScoreChart.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TrendGraph.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProjectSummary.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ExportButton.tsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ exportReport.action.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ audit/                        # FR61-FR69
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auditLogger.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auditLogger.test.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ AuditTrail.tsx
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ project/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProjectCard.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProjectSettings.tsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ FileUpload.tsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ actions/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ createProject.action.ts
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ uploadFile.action.ts
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ admin/
    ‚îÇ       ‚îú‚îÄ‚îÄ components/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ UserManagement.tsx
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ RoleAssignment.tsx
    ‚îÇ       ‚îî‚îÄ‚îÄ actions/
    ‚îÇ           ‚îî‚îÄ‚îÄ updateUserRole.action.ts
    ‚îÇ
    ‚îú‚îÄ‚îÄ lib/                              # Shared utilities
    ‚îÇ   ‚îú‚îÄ‚îÄ env.ts                        # Zod-validated env access (R35)
    ‚îÇ   ‚îú‚îÄ‚îÄ logger.ts                     # pino configuration
    ‚îÇ   ‚îú‚îÄ‚îÄ utils.ts                      # cn(), general utilities
    ‚îÇ   ‚îú‚îÄ‚îÄ constants.ts                  # App-wide constants
    ‚îÇ   ‚îú‚îÄ‚îÄ supabase/                     # Client factories (R36)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.ts                 # Server Component/Action client
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.ts                 # Browser client
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin.ts                  # Admin/service role (server-only)
    ‚îÇ   ‚îú‚îÄ‚îÄ inngest/                      # Inngest client (R44)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.ts                 # Inngest client instance
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts                  # Re-export
    ‚îÇ   ‚îú‚îÄ‚îÄ auth/                         # Auth helpers (R45)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requireRole.ts            # Server-side role check (M3)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requireRole.test.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ getCurrentUser.ts         # Get user + tenant from session
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ getCurrentUser.test.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ ai/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ providers.ts              # Multi-provider config
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fallbackChain.ts          # Version pin + fallback
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fallbackChain.test.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ costTracker.ts            # Token + cost logging (R30)
    ‚îÇ   ‚îî‚îÄ‚îÄ language/
    ‚îÇ       ‚îú‚îÄ‚îÄ segmenter.ts              # Intl.Segmenter (CJK/Thai)
    ‚îÇ       ‚îú‚îÄ‚îÄ segmenter.test.ts
    ‚îÇ       ‚îî‚îÄ‚îÄ rules/
    ‚îÇ           ‚îú‚îÄ‚îÄ index.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ thai.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ japanese.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ chinese.ts
    ‚îÇ           ‚îî‚îÄ‚îÄ korean.ts
    ‚îÇ
    ‚îú‚îÄ‚îÄ db/                               # Database layer (Drizzle)
    ‚îÇ   ‚îú‚îÄ‚îÄ index.ts                      # Drizzle client export
    ‚îÇ   ‚îú‚îÄ‚îÄ connection.ts                 # DB connection config (R46)
    ‚îÇ   ‚îú‚îÄ‚îÄ schema/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts                  # Re-export all schemas
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tenants.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ files.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segments.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ findings.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scores.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reviewSessions.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ glossaries.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ taxonomies.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auditLogs.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ userRoles.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feedbackEvents.ts            # MVP: Review feedback for Growth ML training
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ languagePairConfigs.ts       # Per-language thresholds (Decision 3.6)
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ relations.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ migrations/                   # Drizzle-generated SQL
    ‚îÇ   ‚îú‚îÄ‚îÄ helpers/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ withTenant.ts             # Tenant filter helper
    ‚îÇ   ‚îú‚îÄ‚îÄ validation/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.ts                   # drizzle-zod generated
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extended.ts               # Custom Zod extensions
    ‚îÇ   ‚îî‚îÄ‚îÄ __tests__/
    ‚îÇ       ‚îî‚îÄ‚îÄ rls/
    ‚îÇ           ‚îú‚îÄ‚îÄ findings.rls.test.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ projects.rls.test.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ auditLogs.rls.test.ts
    ‚îÇ           ‚îî‚îÄ‚îÄ glossaries.rls.test.ts
    ‚îÇ
    ‚îú‚îÄ‚îÄ stores/                           # Global Zustand stores
    ‚îÇ   ‚îú‚îÄ‚îÄ ui.store.ts
    ‚îÇ   ‚îî‚îÄ‚îÄ keyboard.store.ts             # Cross-feature shortcuts (R17)
    ‚îÇ
    ‚îú‚îÄ‚îÄ styles/
    ‚îÇ   ‚îú‚îÄ‚îÄ tokens.css                    # Design system CSS properties (R22)
    ‚îÇ   ‚îî‚îÄ‚îÄ animations.css                # Shared transitions (R22)
    ‚îÇ
    ‚îú‚îÄ‚îÄ test/                             # Shared test utilities
    ‚îÇ   ‚îú‚îÄ‚îÄ factories.ts                  # Test data factories (R42)
    ‚îÇ   ‚îú‚îÄ‚îÄ setup.ts                      # Global test setup
    ‚îÇ   ‚îú‚îÄ‚îÄ helpers.ts                    # Shared test helpers
    ‚îÇ   ‚îú‚îÄ‚îÄ mocks/                        # Standardized mocks (R50)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase.ts              # Mock Auth, Realtime, DB
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inngest.ts               # Mock step.run, events
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai-providers.ts          # Mock OpenAI/Anthropic
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fast-xml-parser.ts       # Mock parser
    ‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                     # Test data files (R51)
    ‚îÇ       ‚îú‚îÄ‚îÄ segments/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ simple.json
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ with-findings.json
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ cjk-thai.json
    ‚îÇ       ‚îú‚îÄ‚îÄ sdlxliff/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ minimal.sdlxliff
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ with-namespaces.sdlxliff
    ‚îÇ       ‚îî‚îÄ‚îÄ glossary/
    ‚îÇ           ‚îî‚îÄ‚îÄ sample-terms.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ types/                            # Shared TypeScript types
    ‚îÇ   ‚îú‚îÄ‚îÄ index.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ finding.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ review.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.ts
    ‚îÇ   ‚îî‚îÄ‚îÄ actionResult.ts              # ActionResult<T> (R11)
    ‚îÇ
    ‚îî‚îÄ‚îÄ middleware.ts                     # Edge: auth + tenant + rate limit
```

### Requirements to Structure Mapping

| FR Category | Feature Module | Key Files |
|-------------|---------------|-----------|
| FR1-FR9: File Parsing | `features/parser/` | sdlxliffParser, excelParser, segmentExtractor |
| FR10-FR16: Dual Taxonomy | `features/taxonomy/` + `features/pipeline/layers/ruleLayer` | TaxonomyConfig, severityWeights, ruleLayer |
| FR17-FR22: AI/LLM | `features/pipeline/layers/` + `lib/ai/` | aiScreeningLayer, deepAiLayer, fallbackChain |
| FR23-FR30: Scoring | `features/scoring/` | mqmCalculator, scoreLifecycle, ScoreDisplay |
| FR31-FR40: Review | `features/review/` | ReviewPanel, FindingCard, keyboard shortcuts |
| FR41-FR45, FR72: Glossary | `features/glossary/` | GlossaryEditor, multiTokenMatcher |
| FR46-FR50: Language Bridge | `features/review/components/LanguageBridge` | LanguageBridge |
| FR51-FR60: Reporting | `features/dashboard/` | ScoreChart, TrendGraph, exportReport |
| FR61-FR69: Audit | `features/audit/` + `db/schema/auditLogs` | auditLogger, AuditTrail |
| FR70-FR72: Score Lifecycle | `features/scoring/` + `features/pipeline/inngest/` | scoreLifecycle, scoreRecalculator |
| FR-SH1-18: Self-healing | `features/self-healing/` (Growth ‚Äî future) | fixAgent, judgeAgent, ragPipeline |
| Feedback Data (Growth foundation) | `db/schema/feedbackEvents.ts` + review actions | feedbackEvents table, collected in MVP |
| Language-pair Config | `db/schema/languagePairConfig.ts` | Per-language thresholds, word segmenter config |

### Cross-Cutting Concern Mapping

| Concern | Primary Files |
|---------|--------------|
| Multi-tenancy | `db/helpers/withTenant.ts`, `middleware.ts`, `supabase/migrations/002_rls_policies.sql` |
| Authentication | `middleware.ts`, `lib/supabase/server.ts`, `lib/auth/`, `app/(auth)/` |
| RBAC | `db/schema/userRoles.ts`, `lib/auth/requireRole.ts`, M3 in Server Actions |
| Audit Trail | `features/audit/auditLogger.ts` ‚Äî called from every Server Action |
| AI Cost Tracking | `lib/ai/costTracker.ts` ‚Äî logged in every pipeline layer |
| CJK/Thai | `lib/language/segmenter.ts` ‚Äî used by parser + rule layer + scoring |
| Error Boundaries | `app/error.tsx`, `app/(app)/error.tsx`, `app/(app)/projects/[projectId]/error.tsx` |

### Architectural Boundaries

**Data Flow:**
```
Upload ‚Üí Parser ‚Üí Segments (DB)
                       ‚Üì
              Inngest Orchestrator (reads project config: Economy/Thorough)
                    ‚Üì          ‚Üì          ‚Üì
               Batch 1      Batch 2    Batch N   (grouped by language pair)
                 ‚Üì per segment
              L1 (Rules) ‚Üí L2 (AI Screen) ‚Üí L3 (Deep AI, if Thorough)
                 ‚Üì
              Findings (DB) ‚Üí Score Aggregation (atomic)
                 ‚Üì
              Supabase Realtime ‚Üí Zustand Store ‚Üí UI
                 ‚Üì
              Review Actions ‚Üí finding.changed event ‚Üí Score Recalculation
                 ‚Üì
              Audit Log (append-only, defense-in-depth)
```

**Integration Points:**

| External Service | Integration Files | Purpose |
|-----------------|------------------|---------|
| Supabase Auth | `lib/supabase/`, `middleware.ts`, `lib/auth/` | Authentication, JWT, RBAC |
| Supabase DB | `db/index.ts` (Drizzle), `db/connection.ts` | Data persistence |
| Supabase Storage | `features/project/actions/uploadFile` | File storage |
| Supabase Realtime | `features/*/hooks/useRealtime*` | Live updates |
| Inngest | `app/api/inngest/route.ts`, `lib/inngest/client.ts`, `features/pipeline/inngest/` | Queue |
| OpenAI / Anthropic | `lib/ai/providers.ts`, `lib/ai/fallbackChain.ts` | AI analysis |
| Better Stack | External config (no code files) | Uptime monitoring |
| Vercel | `next.config.ts`, deployment config | Hosting, analytics |

### Vitest Workspace Configuration

```typescript
// vitest.workspace.ts
export default defineWorkspace([
  {
    test: {
      name: 'unit',
      include: ['src/**/*.test.{ts,tsx}'],
      exclude: ['src/db/__tests__/**'],
      environment: 'jsdom',
    }
  },
  {
    test: {
      name: 'rls',
      include: ['src/db/__tests__/rls/**/*.test.ts'],
      environment: 'node',
    }
  }
])
```

## MVP Feedback Data Collection (Growth Foundation)

_This section defines data collection patterns in MVP that provide the training data foundation for Growth-phase Self-healing Translation. Collecting feedback from Day 1 builds a competitive data moat before the Self-healing feature launches._

**Source:** Self-healing Translation Research ‚Äî Recommendation #4: "Build feedback loop infrastructure from day 1 ‚Äî this is our long-term competitive moat"

### Feedback Events Schema

```typescript
// src/db/schema/feedbackEvents.ts
export const feedbackEvents = pgTable('feedback_events', {
  id: uuid('id').primaryKey().defaultRandom(),
  tenantId: uuid('tenant_id').notNull(),
  findingId: uuid('finding_id').notNull().references(() => findings.id),
  projectId: uuid('project_id').notNull().references(() => projects.id),
  reviewerId: uuid('reviewer_id').notNull(),

  // Context for future ML training
  action: varchar('action', { length: 20 }).notNull(),        // 'accept' | 'reject' | 'edit' | 'change_severity'
  findingCategory: varchar('finding_category', { length: 50 }),  // MQM category (accuracy, fluency, etc.)
  findingSeverity: varchar('finding_severity', { length: 20 }),  // original severity
  newSeverity: varchar('new_severity', { length: 20 }),          // if changed

  // Source/Target for training data
  sourceLang: varchar('source_lang', { length: 10 }).notNull(),
  targetLang: varchar('target_lang', { length: 10 }).notNull(),
  sourceText: text('source_text').notNull(),
  originalTarget: text('original_target').notNull(),
  correctedTarget: text('corrected_target'),                     // if reviewer edited the target

  // AI layer metadata
  detectedByLayer: varchar('detected_by_layer', { length: 5 }), // 'L1' | 'L2' | 'L3'
  aiModel: varchar('ai_model', { length: 50 }),                  // model that detected the issue
  aiConfidence: real('ai_confidence'),                            // 0-100 confidence score

  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow(),
})

// Indexes for future ML pipeline queries
// idx_feedback_events_lang_pair: (source_lang, target_lang, action)
// idx_feedback_events_category: (finding_category, action)
// idx_feedback_events_tenant_created: (tenant_id, created_at)
```

### Collection Points (MVP)

Every review action automatically writes to `feedback_events`:

| Review Action | `action` Value | Extra Data Captured |
|--------------|---------------|---------------------|
| Accept finding | `accept` | AI confidence was correct ‚Äî positive signal |
| Reject finding (false positive) | `reject` | AI was wrong ‚Äî negative signal for retraining |
| Edit target text | `edit` | `corrected_target` = gold standard correction |
| Change severity | `change_severity` | `new_severity` = calibration data |

### Implementation Pattern

```typescript
// Inside review Server Actions (e.g., acceptFinding.action.ts)
// After updating finding status, also write feedback event:
await db.insert(feedbackEvents).values({
  tenantId, findingId, projectId, reviewerId,
  action: 'accept',
  findingCategory: finding.category,
  findingSeverity: finding.severity,
  sourceLang, targetLang,
  sourceText: segment.source,
  originalTarget: segment.target,
  detectedByLayer: finding.detectedByLayer,
  aiModel: finding.aiModel,
  aiConfidence: finding.aiConfidence,
})
```

**Performance Impact:** INSERT only, no queries during review flow. Zero impact on P95 latency.

**RLS:** Same policy as findings ‚Äî tenant-scoped, reviewers can INSERT, admins can SELECT for analytics.

**Data Volume Estimate:** ~10-50 events per review session √ó ~20 sessions/day = 200-1,000 rows/day. Negligible storage cost.

### Value for Growth Phase

| Data Collected | Growth Phase Usage |
|---------------|-------------------|
| Accept/Reject signals | Train confidence calibration per language pair |
| Edited target text | Gold-standard corrections for fine-tuning Fix Agent |
| Category + Severity changes | Calibrate MQM category detection accuracy per model |
| Layer + Model metadata | Evaluate which model performs best per language pair |

**Data Moat Timeline:** After 3-6 months of MVP usage, accumulated feedback_events provide enough training data to fine-tune domain-specific models ‚Äî a competitive advantage no competitor can replicate without similar usage data.

---

## Growth Architecture: Self-healing Translation Foundation

_This section documents architectural patterns from the Self-healing Translation Research that guide Growth-phase implementation. While Self-healing (FR-SH1-18) is not built in MVP, these patterns are documented here to prevent costly retrofitting and ensure MVP decisions do not conflict with Growth requirements._

**Source:** Technical AI/LLM Self-healing Translation Research (2026-02-14) ‚Äî 6 core technologies confirmed feasible with existing stack

### Self-healing Pipeline Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 1: Rule-based Auto-fix (Phase 0)                  ‚îÇ
‚îÇ ‚Üí Tag repair, placeholder restore, number format fix    ‚îÇ
‚îÇ ‚Üí 99% safe, zero cost, instant                          ‚îÇ
‚îÇ ‚Üí Uses existing L1 rule layer infrastructure             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 2: AI Quick-fix Agent                             ‚îÇ
‚îÇ ‚Üí Terminology corrections, obvious fluency fixes        ‚îÇ
‚îÇ ‚Üí GPT-4o-mini (same as L2 screening)                   ‚îÇ
‚îÇ ‚Üí RAG: glossary + translation memory retrieval          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 3: Deep AI Fix Agent + Judge Agent                ‚îÇ
‚îÇ ‚Üí Fix Agent: Claude Sonnet generates correction         ‚îÇ
‚îÇ ‚Üí Judge Agent: Separate model verifies fix quality      ‚îÇ
‚îÇ ‚Üí Prevents self-evaluation bias (research finding)      ‚îÇ
‚îÇ ‚Üí RUBRIC-MQM span-level confidence scoring              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 4: Progressive Trust Routing                      ‚îÇ
‚îÇ ‚Üí üü¢ High confidence (>95%) ‚Üí Auto-apply (Autonomous)  ‚îÇ
‚îÇ ‚Üí üü° Medium (70-95%) ‚Üí 1-click apply (Assisted)        ‚îÇ
‚îÇ ‚Üí üî¥ Low (<70%) ‚Üí Flag for review (Shadow)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Architectural Patterns (from Research)

**1. Fix Agent + Judge Agent (Decoupled Verification)**
- Fix Agent generates corrections using RAG-augmented prompts
- Judge Agent (different model or prompt) evaluates fix quality independently
- Prevents hallucination propagation ‚Äî wrong fixes destroyed before user sees them
- MVP Inngest pipeline already supports multi-step execution (reuse same infrastructure)

**2. Progressive Trust Model**
- **Shadow Mode:** AI generates fix suggestions, displays alongside findings, but never auto-applies. Reviewer sees "suggested fix" badge. All accept/reject tracked in `feedback_events`.
- **Assisted Mode:** High-confidence fixes presented as 1-click apply. Reviewer can accept with single action.
- **Autonomous Mode:** Highest-confidence fixes auto-applied. Reviewer can override. Requires 2+ months of calibration data per language pair.
- **Kill Criteria:** Revert rate > 15% (rolling 500 fixes) ‚Üí regress to previous trust level

**3. RAG Pipeline (pgvector)**
- Supabase already includes pgvector extension ‚Äî no new infrastructure needed
- Embed glossary terms + translation memory segments for retrieval
- Fix Agent prompt = source + target + retrieved glossary context + retrieved TM examples
- Embedding model: text-embedding-3-small (OpenAI) ‚Äî $0.02/1M tokens, sufficient quality

**4. Constrained Decoding for XLIFF Integrity**
- Vercel AI SDK structured output (Zod schemas) enforces tag/placeholder preservation
- Fix must preserve all XLIFF tags, placeholders (`{0}`, `%s`), and HTML entities
- Schema validation: original tags == fixed tags (post-processing check)

### Integration Points with MVP Architecture

| MVP Component | Growth Self-healing Usage |
|--------------|--------------------------|
| Inngest pipeline (3-tier) | Add fix steps after detection steps ‚Äî same orchestrator |
| `feedback_events` table | Training data for confidence calibration + fine-tuning |
| `language_pair_configs` table | Per-language confidence thresholds for Progressive Trust |
| `lib/ai/providers.ts` | LAYER_MODELS config extends to Fix Agent + Judge Agent models |
| `lib/ai/fallbackChain.ts` | Same fallback pattern applies to fix generation |
| Supabase Realtime | Push fix suggestions to review UI in real-time |
| Zustand `useReviewStore` | Extend with `suggestedFix` field per finding |
| Audit log (3-layer) | All auto-fixes logged with full provenance |

### Future File Structure (Growth)

```
src/features/self-healing/
  agents/
    fixAgent.ts              # Fix generation with RAG context
    judgeAgent.ts            # Independent fix verification
  inngest/
    selfHealingOrchestrator.ts  # Orchestrate fix pipeline
    fixBatchWorker.ts        # Batch fix generation
  components/
    SuggestedFix.tsx         # Fix suggestion UI with 1-click apply
    FixConfidenceBadge.tsx   # Confidence visualization
    TrustLevelIndicator.tsx  # Shadow/Assisted/Autonomous status
  hooks/
    useSuggestedFixes.ts     # Realtime fix subscription
  stores/
    selfHealing.store.ts     # Fix state management
  actions/
    applyFix.action.ts       # Apply suggested fix
    rejectFix.action.ts      # Reject and log feedback
```

### Phased Implementation Roadmap (from Research)

| Phase | Name | Scope | Data Requirement |
|:-----:|------|-------|-----------------|
| 0 | Rule-based Auto-fix | Tag repair, placeholder restore (L1 only) | None ‚Äî deterministic rules |
| 1 | Shadow Mode | AI generates fixes, displays alongside findings, never auto-applies | Needs ~1,000 feedback_events per language pair |
| 2 | Assisted Mode | 1-click apply for high-confidence fixes | Needs ~5,000 feedback_events + calibrated thresholds |
| 3 | Autonomous Mode | Auto-apply highest-confidence fixes | Needs ~10,000 feedback_events + proven accuracy |

### Cost Projection (from Research)

Self-healing adds fix generation cost on top of QA detection:

| Component | Per 100K Words | Notes |
|-----------|:--------------:|-------|
| QA Detection (MVP) | $0.40 - $2.40 | Economy vs Thorough |
| Fix Generation (Growth) | $1.50 - $3.00 | Fix Agent + Judge Agent |
| **Total with Self-healing** | **$1.90 - $5.40** | Still 70-85% cheaper than human QA ($150-300) |

---

## Architecture Validation Results

### Coherence Validation ‚úÖ

**Decision Compatibility:** All 9 core technologies verified compatible. No version conflicts detected. Next.js 16 + Tailwind v4 + shadcn/ui + Drizzle 0.45.1 + Supabase 2.95.3 + Inngest 3.52.0 + AI SDK v6 + pino + fast-xml-parser 5.3.5 all work together without issues.

**Pattern Consistency:** The following patterns are internally consistent with no contradictions:

- Naming conventions: DB snake_case maps to JSON camelCase via Drizzle
- Error handling: ActionResult for Server Actions, Error Boundary for unexpected errors
- Auth patterns: M3 JWT for reads, DB lookup for writes
- Audit patterns: 3-layer defense-in-depth

**Structure Alignment:** Feature-based organization aligns with RSC boundary strategy. Server Actions co-located in feature folders. Inngest functions in features with registry in api/. Test co-location with Vitest workspace separation (jsdom for components, node for RLS).

### Requirements Coverage ‚úÖ

**Functional Requirements:**
- 80 FRs (68 MVP + 12 Growth): 100% architecturally supported
- 18 FR-SH (Self-healing): Deferred to Growth by design ‚Äî Growth Architecture section documents pipeline, patterns, integration points, and phased roadmap. MVP collects feedback data for future training.
- All 10 FR categories mapped to specific feature modules and files

**Non-Functional Requirements:**
- 42 NFRs + 7 NFR-SH: All addressed through architectural decisions
- Performance: Caching strategy + batch processing + benchmark gate
- Security: M3 RBAC + RLS Day 1 + 3-layer audit + rate limiting
- Reliability: AI fallback chain + Inngest retry + monitoring stack
- Accessibility: WCAG 2.1 AA patterns + keyboard-first
- Cost: Economy/Thorough mode routing + cost tracking per request

**PRD Handoff Items:** 8/8 resolved in architectural decisions

### Implementation Readiness ‚úÖ

**Decision Completeness:**
- 24 architectural decisions across 5 categories ‚Äî all documented with rationale
- 9 technology versions verified via web search (February 2026)
- Initialization command sequence provided (4 steps)

**Structure Completeness:**
- ~120+ files/directories defined in complete project tree
- All FR categories mapped to specific file locations
- 7 cross-cutting concerns mapped to primary files
- Integration points for 8 external services defined

**Pattern Completeness:**
- 57 refinements applied (R1-R52 Party Mode + R53-R57 Research Integration) from 5 review rounds
- 15 anti-patterns documented
- Code examples for all major patterns
- Test conventions with workspace configuration

### Gap Analysis

**Critical Gaps:** 0

**Important Gaps (non-blocking):**

| # | Gap | Impact | Resolution |
|---|-----|--------|------------|
| G1 | DB Schema ERD not included | Developers infer relationships from schema files | Create ERD as part of first implementation story |
| G2 | API rate limit values not specified | Developers implement rate limits without consistent values | Define in story: 100 req/min per user default |
| G3 | ~~Self-healing feature structure not detailed~~ | ~~No MVP impact~~ | ‚úÖ Addressed ‚Äî Growth Architecture section added with pipeline, file structure, and phased roadmap |

**Nice-to-Have Gaps:**

| # | Gap | Recommendation |
|---|-----|---------------|
| G4 | Storybook for shared components | Add post-MVP if component library grows |
| G5 | OpenTelemetry tracing | Consider for pipeline performance profiling in Growth |

### Architecture Completeness Checklist

**‚úÖ Requirements Analysis (Step 2)**
- [x] Project context thoroughly analyzed (80 FRs, 42 NFRs, 18 FR-SH, 7 NFR-SH)
- [x] Scale and complexity assessed (High ‚Äî full-stack, multi-tenant, 3-layer AI pipeline)
- [x] Technical constraints identified (7 key constraints)
- [x] Cross-cutting concerns mapped (10 concerns)
- [x] 8 Architecture handoff items from PRD Validation documented

**‚úÖ Starter Template (Step 3)**
- [x] Technology versions verified via web search (9 technologies)
- [x] Starter approach selected with rationale
- [x] Initialization command sequence documented

**‚úÖ Architectural Decisions (Step 4)**
- [x] 5 categories of decisions made collaboratively
- [x] 21 specific decisions documented with rationale
- [x] All 8 PRD handoff items resolved
- [x] Party Mode review on all 5 categories (R1-R32)

**‚úÖ Implementation Patterns (Step 5)**
- [x] Naming conventions established (DB, API, code, test)
- [x] Structure patterns defined (co-location, imports, exports)
- [x] Communication patterns specified (events, Realtime, Zustand)
- [x] Process patterns documented (error handling, loading, auth)
- [x] Data access patterns defined (Drizzle only, Supabase client factories)
- [x] Accessibility patterns defined (WCAG 2.1 AA)
- [x] 15 anti-patterns listed
- [x] Party Mode review (R33-R43)

**‚úÖ Project Structure (Step 6)**
- [x] Complete directory structure defined (~120+ files)
- [x] Component boundaries established (feature-based + shared)
- [x] Integration points mapped (8 external services)
- [x] Requirements to structure mapping complete (all FR categories)
- [x] Vitest workspace configuration defined
- [x] Party Mode review (R44-R52)

### Architecture Readiness Assessment

**Overall Status:** ‚úÖ READY FOR IMPLEMENTATION

**Confidence Level:** HIGH

**Key Strengths:**
- Thoroughly validated through 5 rounds of Party Mode review (52 refinements) + 5 Research Integration refinements (R53-R57)
- All 8 PRD handoff items resolved with specific decisions
- Complete project structure with ~120+ files mapped to requirements
- Defense-in-depth security (M3 RBAC, RLS Day 1, 3-layer audit)
- Comprehensive patterns prevent AI agent implementation conflicts
- Performance gates and benchmarks defined before MVP ship

**Areas for Future Enhancement:**
- DB Schema ERD (create during first implementation story)
- Rate limit configuration (define in implementation stories)
- ~~Self-healing feature architecture~~ ‚úÖ Growth Architecture section added (R56)
- Storybook for component library (post-MVP)
- OpenTelemetry tracing (Growth phase)

### Implementation Handoff

**AI Agent Guidelines:**
1. Follow all architectural decisions exactly as documented
2. Use implementation patterns consistently across all components
3. Respect project structure and boundaries ‚Äî files go where specified
4. Refer to this document for all architectural questions
5. Follow the 15 anti-patterns list ‚Äî violations must be fixed before merge
6. Every Server Action must return ActionResult<T> and write audit log
7. Every Inngest step must have deterministic ID for idempotency
8. Every component must follow accessibility patterns (WCAG 2.1 AA)

**First Implementation Priority:**
```bash
# Step 1: Initialize project
npx create-next-app@latest qa-localization-tool --typescript --tailwind --eslint --app --src-dir

# Step 2: Initialize shadcn/ui
npx shadcn@latest init

# Step 3: Install core dependencies
npm i @supabase/supabase-js @supabase/ssr drizzle-orm inngest ai fast-xml-parser zustand pino sonner zod

# Step 4: Install dev dependencies
npm i -D drizzle-kit @types/node vitest @vitejs/plugin-react jsdom @testing-library/react @faker-js/faker playwright @playwright/test drizzle-zod

# Step 5: Set up project structure as defined in this document
```

**Implementation Sequence:**
1. Project initialization + folder structure + design tokens
2. DB schema (Drizzle) + RLS policies + audit trigger
3. Supabase Auth + RBAC (JWT + user_roles + M3 helpers)
4. Edge middleware + rate limiting
5. Feature modules: parser ‚Üí pipeline ‚Üí scoring ‚Üí review ‚Üí glossary ‚Üí dashboard ‚Üí audit
6. CI/CD pipeline (GitHub Actions)
7. Monitoring (Vercel Analytics + Better Stack)
