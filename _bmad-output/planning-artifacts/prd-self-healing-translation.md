---
workflowStatus: 'DRAFT'
createdAt: '2026-02-14'
classification:
  projectType: 'Feature Extension ‚Äî Self-healing Translation'
  domain: 'Localization Technology / AI-powered Auto-correction'
  complexity: 'High'
  prerequisite: 'Core QA MVP operational (FR1-FR72) + Growth foundation (FR73-FR75 rule-based auto-fix)'
parentPRD: '_bmad-output/planning-artifacts/prd.md'
researchSource: '_bmad-output/planning-artifacts/research/technical-ai-llm-self-healing-translation-research-2026-02-14.md'
author: Mona
date: '2026-02-14'
lastEdited: '2026-02-14'
editHistory:
  - date: '2026-02-14'
    changes: 'BMAD Validation Round 1 fixes: Kill Criteria ‚Äî added acceptance threshold gap 40-75% behavior, added 7-day rolling window to revert rate, clarified 2,000 aggregate vs 500 per-language-pair thresholds. FR-SH11 ‚Äî added rolling 500-fix accuracy window. Density ‚Äî "Requires minimum" ‚Üí "Needs". Leakage ‚Äî FR-SH1 "Zod schema" ‚Üí "structured output validation"'
  - date: '2026-02-14'
    changes: 'Party Mode review fixes: reconciled kill criteria (< 60% deprioritize / 60-85% retune / > 85% gate), clarified FR-SH18 budget is separate from FR71, added data dependency + 500+ corrections requirement to Shadow Mode, added Shadow Mode adaptive sampling strategy, linked Journey 7 as evolution of Journey 2'
  - date: '2026-02-14'
    changes: 'Initial creation ‚Äî derived from Self-healing Translation research + main PRD integration (Option B+)'
---

# Self-healing Translation PRD ‚Äî AI-powered Auto-correction for QA Localization Tool

**Author:** Mona
**Date:** 2026-02-14
**Status:** DRAFT
**Prerequisite:** Core QA MVP operational (main PRD FR1-FR72) + Growth foundation (FR73-FR75 rule-based auto-fix)

---

## 1. Executive Summary

### Vision

Transform the QA localization tool from a **Detective** (detects errors, reports to humans) into a **Doctor** (detects errors, diagnoses root cause, prescribes verified corrections for human approval). This is the paradigm shift from "detect-report-fix" to "detect-autofix-approve."

### Core Innovation

**Self-healing Translation** ‚Äî The system doesn't just find errors; it generates verified corrections using a multi-agent AI pipeline (Fix Agent + Judge Agent) with progressive trust (Shadow ‚Üí Assisted ‚Üí Autonomous), reducing reviewer effort by 60-80% while maintaining quality through human oversight.

### Why Now

- LLM-based Automatic Post-Editing (APE) achieves **near human-level quality** (closing quality gap by 43%)
- AI localization market projected to reach **$7.5 billion by 2028** (CAGR 18%)
- LLM translation costs dropping from $10 to **$2 per 1,000 words by 2028**
- **No competitor** offers standalone AI auto-fix in a QA tool ‚Äî first-to-market opportunity
- Our tech stack (Vercel AI SDK 6, Supabase pgvector, Inngest) supports the full architecture **without new infrastructure**

### Relationship to Main PRD

This PRD extends the main PRD (`prd.md`) with Self-healing capabilities:

| Main PRD (Core QA) | This PRD (Self-healing) |
|-------|------|
| Detects issues (3-Layer Pipeline) | Generates fixes for detected issues |
| Suggests what's wrong | Suggests how to fix + provides correction |
| Human reviews findings | Human approves/modifies fixes |
| FR1-FR72 (MVP) + FR73-FR75 (Growth) | FR-SH1 through FR-SH18 |
| MVP ‚Üí Growth ‚Üí Vision | Growth ‚Üí Vision (builds on MVP core) |

**Foundation already in main PRD:**
- FR73-FR75: Rule-based auto-fix (Growth) ‚Äî deterministic fixes for tags, placeholders, numbers. Schema design included in MVP
- FR64-FR69: AI Learning & Trust ‚Äî feedback loop infrastructure
- Pillar 5: Actionable Suggestions ‚Äî confidence + accept/reject
- Innovation #6: Self-healing Translation reference

---

## 2. Success Criteria

### Self-healing Value Proposition

**The Aha! Moment:** The first time a reviewer sees an AI-generated fix that's *exactly right* ‚Äî they click "Accept" and the segment is corrected without typing a single character. When this happens consistently, the tool transitions from "QA checker" to "QA + correction partner."

### Success Metrics

| Metric | Shadow Mode Target | Assisted Mode Target | Autonomous Mode Target |
|--------|-------------------|---------------------|----------------------|
| Fix accuracy (accepted without modification) | > 70% (internal tracking) | > 80% (user-visible) | > 95% (auto-apply threshold) |
| Fix acceptance rate | N/A (not shown) | > 60% Accept + < 10% Reject | > 90% auto-accepted |
| Time saved per file | Baseline measurement | 30-40% reduction | 60-80% reduction |
| Cost per fix | Baseline measurement | < $0.05 per fix | < $0.03 per fix |
| Judge Agent agreement with human | > 85% | > 90% | > 95% |
| User trust score (survey) | N/A | > 7/10 | > 8/10 |

### Kill Criteria

| Phase | Kill Trigger | Fallback | Decision Point |
|-------|-------------|---------|----------------|
| Shadow Mode | Fix accuracy < 60% after 2,000 fix attempts (aggregate across all language pairs) ‚Üí deprioritize; 60-85% ‚Üí stay in Shadow + retune prompts. Gate to Assisted requires > 85% for 500+ fixes per individual language pair | If < 60%: deprioritize feature. If 60-85%: retune prompts, adjust RAG context, re-evaluate at 5,000 attempts | Month 4 |
| Assisted Mode | Acceptance rate < 40% after 4 weeks ‚Üí kill; 40-75% ‚Üí continue Assisted Mode, monitor weekly, retune prompts; > 75% ‚Üí gate to Autonomous | If < 40%: revert to suggestion-only (no fix proposals). If 40-75%: stay in Assisted, retune, re-evaluate monthly | Month 6 |
| Autonomous Mode | Auto-applied fix revert rate > 5% in any 7-day rolling window | Revert to Assisted Mode permanently | Month 9 |

---

## 3. Product Scope ‚Äî Self-healing Phases

### Phase 0: Foundation (Growth ‚Äî FR73-FR75 in main PRD)

> **Cross-reference:** FR73-FR75 in main PRD (Growth scope ‚Äî moved from MVP per PM review 2026-02-14). MVP includes only schema design (fix_suggestions, self_healing_config tables with mode="disabled") for Growth readiness.

- Rule-based auto-fix for deterministic categories (tags, placeholders, numbers)
- Auto-fix preview with before/after comparison
- Auto-fix acceptance tracking per category per language pair
- Data structures designed for future AI fix storage (fix_suggestions table, shadow_results table) ‚Äî **schema included in MVP**

### Phase 1: Shadow Mode (Growth ‚Äî Month 3-4)

**Goal:** Calibrate AI fix accuracy per language pair without user impact.

**Data Dependency:** Needs **500+ human-corrected translations per language pair** from reviewer actions during MVP usage (Accept/Reject/Flag decisions from FR64). See `data-requirements-and-human-feedback-plan.md` Section A3 for test data specifications. Shadow Mode accuracy is measured by comparing AI-generated fix against reviewer's actual manual correction.

- AI generates fix suggestions for detected issues using **adaptive sampling** (see Shadow Mode Sampling Strategy below)
- Fixes stored but NOT shown to users
- Internal dashboard tracks: fix accuracy (compared to reviewer's manual fix), cost per fix, latency
- Per-language pair confidence thresholds established
- Judge Agent validates fix quality independently
- **Gate to Phase 2:** Shadow Mode accuracy > 85% per language pair for 500+ fixes

### Phase 2: Assisted Mode (Growth ‚Äî Month 5-6)

**Goal:** Show AI fixes to reviewers for Accept/Modify/Reject.

- AI fix suggestions displayed alongside each finding with confidence score
- Reviewer can: Accept (apply as-is), Modify (edit and apply), Reject (dismiss fix)
- Every decision feeds learning loop (RAG update + prompt optimization)
- Fix quality indicators: confidence score, Judge Agent verification status, similar fixes history
- Bulk accept for high-confidence fixes (> 90%)
- **Gate to Phase 3:** Acceptance rate > 75% AND Judge agreement > 90% for 1,000+ fixes

### Phase 3: Autonomous Mode (Vision ‚Äî Month 8+)

**Goal:** Auto-apply high-confidence verified fixes with human oversight.

- Fixes with confidence > 95% AND Judge Agent verified ‚Üí auto-applied
- Auto-applied fixes visible in review with "auto-fixed (AI)" badge + one-click revert
- Medium confidence (80-95%) ‚Üí suggested with prominent display
- Low confidence (< 80%) ‚Üí flagged only, no fix proposed
- Progressive trust per language pair √ó fix category (can regress)
- Dashboard shows: auto-fix rate, revert rate, cost savings, time saved

---

## 4. User Journey 7: ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏û‡∏£ ‚Äî "The Self-healing Day" (Growth Phase, Month 5+)

> **Evolution of Journey 2:** This journey builds directly on Journey 2 "‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏û‡∏£ ‚Äî Single-Pass Day" (main PRD Section 4). In Journey 2, ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏û‡∏£ reviews 12 files in a single pass using AI detection + auto-pass. Journey 7 extends this by adding AI-generated fix suggestions ‚Äî reducing manual correction work from ~4 hours to ~2 hours for 8 files. The same trust-building pattern from Journey 1-2 (verify everything ‚Üí spot-check ‚Üí glance & confirm) applies here for fix acceptance.

**Opening Scene:** ‡πÄ‡∏ä‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡∏≠‡∏±‡∏á‡∏Ñ‡∏≤‡∏£ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏û‡∏£‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≠‡∏ï‡∏£‡∏ß‡∏à 8 ‡πÑ‡∏ü‡∏•‡πå ‡πÄ‡∏ò‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤ icon ‡πÉ‡∏´‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≤‡∏á findings ‚Äî üíä "AI Fix Available" ‡πÄ‡∏ò‡∏≠‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô‡∏°‡∏±‡∏ô‡πÉ‡∏ô announcement ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏•‡∏≠‡∏á

**Rising Action:**
1. ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å ‚Äî findings ‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏ï‡πà‡∏°‡∏µ üíä icon ‡∏Ç‡πâ‡∏≤‡∏á 12 ‡∏à‡∏≤‡∏Å 18 findings
2. ‡∏Å‡∏î üíä ‡∏ó‡∏µ‡πà finding ‡πÅ‡∏£‡∏Å: "Missing tag `<b>` in target" ‚Üí AI Fix: `‡πÄ‡∏û‡∏¥‡πà‡∏° <b> ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'` ‚Üí Preview ‡πÅ‡∏™‡∏î‡∏á before/after ‚Üí Confidence 98% ‚úÖ Judge Verified
3. ‡πÄ‡∏ò‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ò‡∏≠‡∏à‡∏∞‡πÅ‡∏Å‡πâ‡πÄ‡∏≠‡∏á... "‡∏ï‡∏£‡∏á‡πÄ‡∏•‡∏¢" ‚Üí ‡∏Å‡∏î **Accept**
4. Finding ‡∏ó‡∏µ‡πà 2: "Semantic error ‚Äî 'bank' translated as '‡∏£‡∏¥‡∏°‡∏ù‡∏±‡πà‡∏á' should be '‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£'" ‚Üí AI Fix: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `‡∏£‡∏¥‡∏°‡∏ù‡∏±‡πà‡∏á‡πÅ‡∏°‡πà‡∏ô‡πâ‡∏≥` ‡πÄ‡∏õ‡πá‡∏ô `‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£` ‚Üí Confidence 91% ‚úÖ Judge Verified
5. ‡πÄ‡∏ò‡∏≠‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤... context ‡∏ñ‡∏π‡∏Å ‚Üí ‡∏Å‡∏î **Accept**
6. Finding ‡∏ó‡∏µ‡πà 5: "Potential overtranslation" ‚Üí AI Fix: ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ `‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å` ‡∏≠‡∏≠‡∏Å ‚Üí Confidence 72% ‚ö†Ô∏è Judge: "Borderline" ‚Üí ‡πÄ‡∏ò‡∏≠‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‚Üí ‡∏Å‡∏î **Modify** ‚Üí ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô `‡∏°‡∏≤‡∏Å` ‡πÅ‡∏ó‡∏ô (‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)

**Climax:** ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà 4 ‚Äî ‡πÄ‡∏ò‡∏≠‡πÄ‡∏´‡πá‡∏ô 15 fixes ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î confidence > 90% ‚Üí ‡∏Å‡∏î **"Bulk Accept All High-Confidence"** ‚Üí 15 fixes applied ‡πÉ‡∏ô 1 click ‚Üí ‡πÄ‡∏ò‡∏≠ spot-check 3 fixes ‚Üí ‡∏ñ‡∏π‡∏Å‡∏´‡∏°‡∏î ‚Üí ‡∏¢‡∏¥‡πâ‡∏°

**Resolution:** ‡∏™‡∏¥‡πâ‡∏ô‡∏ß‡∏±‡∏ô ‡πÄ‡∏ò‡∏≠‡∏ï‡∏£‡∏ß‡∏à 8 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô 2 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞ 4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏õ‡∏Å‡∏ï‡∏¥ 73% ‡∏Ç‡∏≠‡∏á fixes ‡∏ñ‡∏π‡∏Å accept ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ ‡πÄ‡∏ò‡∏≠‡∏ö‡∏≠‡∏Å‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡∏°‡∏ß‡πà‡∏≤ "‡∏°‡∏±‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏µ junior proofreader ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ ‡πÅ‡∏Ñ‡πà‡∏ï‡πâ‡∏≠‡∏á double-check ‡πÄ‡∏â‡∏¢‡πÜ"

**Trust Building Path:**
> - **Week 1:** ‡πÄ‡∏ò‡∏≠ verify ‡∏ó‡∏∏‡∏Å fix ‡∏Å‡πà‡∏≠‡∏ô accept (spot-check 100%)
> - **Week 2-3:** ‡πÄ‡∏ò‡∏≠ spot-check 50% ‡∏Ç‡∏≠‡∏á high-confidence fixes
> - **Month 2+:** ‡πÄ‡∏ò‡∏≠ bulk accept high-confidence, spot-check 20%
> - **Month 4+ (Autonomous):** System auto-applies high-confidence ‚Üí ‡πÄ‡∏ò‡∏≠‡∏î‡∏π‡πÅ‡∏Ñ‡πà medium + low confidence

> **Requirements revealed:** AI Fix display alongside findings, Confidence score per fix, Judge Agent verification status, Accept/Modify/Reject actions, Before/after preview, Bulk accept for high-confidence, Fix accuracy tracking, Modify action preserves partial fix, Trust-building through gradual confidence, Auto-fix badge with revert capability

---

## 5. Self-healing Architecture

### 4-Layer Self-healing Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    QA Finding Detected                          ‚îÇ
‚îÇ              (from existing 3-Layer QA Pipeline)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Layer 1: Rule-based     ‚îÇ  FREE, INSTANT
          ‚îÇ  Auto-fix                ‚îÇ  Tags, placeholders, numbers
          ‚îÇ  (FR73 ‚Äî Growth)         ‚îÇ  100% deterministic
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ If not rule-fixable
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Layer 2: AI Screening   ‚îÇ  CHEAP, FAST (~2s)
          ‚îÇ  + Quick Fix             ‚îÇ  Simple fixes + flag complex
          ‚îÇ  (FR-SH1, FR-SH2)       ‚îÇ  Vercel AI SDK generateObject
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ If complex/low confidence
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Layer 3: Deep AI Fix    ‚îÇ  PREMIUM, ACCURATE (~5-10s)
          ‚îÇ  + Judge Agent           ‚îÇ  Context-enriched fix + independent verify
          ‚îÇ  (FR-SH3, FR-SH4)       ‚îÇ  RAG context + few-shot examples
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Layer 4: Trust Gateway  ‚îÇ  DECISION POINT
          ‚îÇ                          ‚îÇ  High (>95%) ‚Üí Auto-apply (Vision)
          ‚îÇ  (FR-SH5)               ‚îÇ  Medium (80-95%) ‚Üí Suggest
          ‚îÇ                          ‚îÇ  Low (<80%) ‚Üí Flag only
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Feedback Loop           ‚îÇ  CONTINUOUS LEARNING
          ‚îÇ  Accept/Modify/Reject    ‚îÇ  ‚Üí RAG update
          ‚îÇ  (FR-SH6)               ‚îÇ  ‚Üí Prompt optimization
          ‚îÇ                          ‚îÇ  ‚Üí Confidence recalibration
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Multi-Agent Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Fix Agent     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Judge Agent     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Trust Gateway   ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                   ‚îÇ     ‚îÇ                  ‚îÇ
‚îÇ ‚Ä¢ Generates fix ‚îÇ     ‚îÇ ‚Ä¢ Independent     ‚îÇ     ‚îÇ ‚Ä¢ Confidence     ‚îÇ
‚îÇ ‚Ä¢ Uses RAG      ‚îÇ     ‚îÇ   evaluation      ‚îÇ     ‚îÇ   routing        ‚îÇ
‚îÇ ‚Ä¢ Few-shot      ‚îÇ     ‚îÇ ‚Ä¢ GEMBA-MQM       ‚îÇ     ‚îÇ ‚Ä¢ Auto/Suggest/  ‚îÇ
‚îÇ   examples      ‚îÇ     ‚îÇ   scoring         ‚îÇ     ‚îÇ   Flag           ‚îÇ
‚îÇ ‚Ä¢ Constrained   ‚îÇ     ‚îÇ ‚Ä¢ Hallucination   ‚îÇ     ‚îÇ ‚Ä¢ Audit trail    ‚îÇ
‚îÇ   output        ‚îÇ     ‚îÇ   detection       ‚îÇ     ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñ≤                                                 ‚îÇ
        ‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Feedback Loop ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ              ‚îÇ
                           ‚îÇ ‚Ä¢ RAG update  ‚îÇ
                           ‚îÇ ‚Ä¢ Prompt tune ‚îÇ
                           ‚îÇ ‚Ä¢ Threshold   ‚îÇ
                           ‚îÇ   calibrate   ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Why Decoupled Agents (Fix ‚â† Judge)

| Concern | Single Agent | Decoupled Agents (Our Approach) |
|---------|-------------|-------------------------------|
| Self-evaluation bias | "I generated this, so it must be good" | Judge has no knowledge of Fix Agent's reasoning |
| Hallucination detection | Can't catch its own hallucinations | Judge independently verifies against source/target |
| Cost | 1 API call | 2 API calls (but cheaper models for Judge) |
| Accuracy | ~70-75% | **~85-90%** (research-confirmed improvement) |

---

## 6. Domain-Specific Constraints for Self-healing

### Shadow Mode Sampling Strategy

Shadow Mode does NOT generate fixes for every finding (cost-prohibitive). Instead, **adaptive sampling** balances training signal quality with cost:

| Phase | Sampling Rate | Rationale |
|-------|:------------:|-----------|
| First 500 findings per language pair | 100% | Maximum training signal for initial calibration |
| 500-2,000 findings | 50% | Sufficient data, reduce cost |
| 2,000+ findings | 25% (random) + 100% (new fix categories) | Focus budget on novel patterns |

**Cost control:** Shadow Mode sampling is subject to FR-SH18 budget cap. If budget exhausted, sampling pauses until next month. NFR-SH3 (< 20% overhead) is measured against the sampled workload, not 100% of findings.

### Fix Generation Constraints

| Constraint | Risk | Mitigation |
|-----------|------|-----------|
| **XLIFF tag preservation** | AI-generated fix corrupts inline tags | Constrained decoding: Zod schema enforces tag structure; post-validation checks tag count/order match source |
| **Glossary compliance** | Fix uses wrong terminology | RAG retrieves project glossary before fix generation; Judge verifies glossary term usage |
| **Cultural appropriateness** | Fix is technically correct but culturally wrong | Per-language-pair calibration; CJK/Thai fixes require higher confidence threshold (+5%) |
| **Context window limits** | Long segments lose surrounding context | Sliding window with overlap; include ¬±3 surrounding segments as context |
| **Fix introduces new errors** | Fix resolves one issue but creates another | Judge Agent checks fix against ALL rule-based checks (tags, numbers, glossary) before approval |

### Language-Specific Fix Rules

| Language | Special Consideration |
|----------|---------------------|
| **Thai (TH)** | No spaces between words ‚Äî fix must maintain correct word boundaries; Thai numeral ‚Üî Arabic mapping in fixes |
| **Chinese (ZH)** | Simplified ‚Üî Traditional consistency; fullwidth punctuation in fixes |
| **Japanese (JA)** | Mixed scripts ‚Äî fix must use correct script (kanji vs katakana vs hiragana) |
| **RTL (AR, HE)** | Fix must preserve bidi markers and RTL text direction |
| **CJK general** | Higher confidence threshold (+5%) for AI fixes due to complexity |

---

## 7. Functional Requirements ‚Äî Self-healing

> **Numbering:** FR-SH# (Self-Healing) to distinguish from main PRD's FR# sequence.
> **Prerequisite:** All FR-SH requirements depend on core QA pipeline (main PRD FR1-FR72) being operational.

### Fix Generation

- **FR-SH1:** System can generate AI fix suggestions for detected QA findings using the Fix Agent, providing: proposed correction text, confidence score (0-100), fix category (terminology, grammar, semantic, style, tag, formatting), and explanation of why the fix is proposed. Fix Agent uses structured output validation to ensure XLIFF tag preservation
- **FR-SH2:** System can enrich fix generation context using RAG retrieval from project glossary, translation memory, and previously accepted fixes stored as pgvector embeddings in Supabase. Context includes: matching glossary terms, similar past fixes for same language pair, and ¬±3 surrounding segments for discourse context
- **FR-SH3:** System can route fix requests based on complexity: simple fixes (single term, tag, number) ‚Üí Layer 2 quick fix; complex fixes (semantic, multi-segment, cultural) ‚Üí Layer 3 deep fix with enriched context

### Fix Verification

- **FR-SH4:** System can verify fix quality using an independent Judge Agent that evaluates: (a) semantic preservation ‚Äî fix maintains source meaning, (b) glossary compliance ‚Äî fix uses correct project terminology, (c) tag integrity ‚Äî all source tags preserved in fix, (d) fluency ‚Äî fix reads naturally in target language, (e) no new errors introduced ‚Äî fix passes all rule-based checks. Judge Agent outputs: pass/fail verdict, confidence score, and specific concerns if any
- **FR-SH5:** System can route verified fixes through the Trust Gateway: High confidence (>95% + Judge pass) ‚Üí auto-apply eligible (Autonomous Mode only), Medium confidence (80-95% OR Judge concerns) ‚Üí suggest to reviewer, Low confidence (<80% OR Judge fail) ‚Üí flag finding only without fix proposal

### Fix Presentation & User Interaction

- **FR-SH6:** QA Reviewer can view AI fix suggestions alongside findings with: proposed fix text, before/after preview in segment context, confidence score with visual indicator, Judge verification status (‚úÖ Verified / ‚ö†Ô∏è Concerns / ‚ùå Failed), and fix category badge
- **FR-SH7:** QA Reviewer can Accept (apply fix as-is), Modify (edit fix and apply), or Reject (dismiss fix) for each AI fix suggestion. Every action recorded with timestamp, actor, and rationale (optional for Accept, required for Reject)
- **FR-SH8:** QA Reviewer can bulk accept all fixes above a configurable confidence threshold (default 90%) for a single file, with confirmation dialog showing count and lowest confidence fix in the batch
- **FR-SH9:** QA Reviewer can view fix history per segment showing: all proposed fixes, accepted/modified/rejected status, who decided, and when

### Progressive Trust System

- **FR-SH10:** System can operate in Shadow Mode where AI generates fixes silently (not displayed to users), stores results, and tracks accuracy by comparing AI fixes against reviewer's actual corrections. Admin can enable Shadow Mode per project per language pair
- **FR-SH11:** System can transition from Shadow Mode to Assisted Mode when accuracy threshold is met (configurable, default > 85% accuracy measured over the most recent 500 fixes as a rolling window per language pair). Transition is per language pair per project ‚Äî not global. Admin can override to force transition or revert
- **FR-SH12:** System can transition from Assisted Mode to Autonomous Mode when acceptance rate threshold is met (configurable, default > 75% acceptance rate AND > 90% Judge agreement for 1,000+ fixes per language pair). Admin can override. System can auto-revert to Assisted Mode if revert rate exceeds 5% in any 7-day window
- **FR-SH13:** System can display trust level status per language pair: current mode (Shadow/Assisted/Autonomous), accuracy trend, fixes until next threshold, and mode transition history

### Learning & Feedback Loop

- **FR-SH14:** System can update RAG knowledge base when reviewer Accepts or Modifies a fix: accepted fix stored as positive example embedding, modified fix stored as improved example embedding, with source finding and correction pair for future retrieval
- **FR-SH15:** System can recalibrate confidence thresholds per language pair based on accumulated accept/reject/modify signals. Recalibration runs weekly (configurable) and requires minimum 100 new signals since last calibration
- **FR-SH16:** System can display Self-healing analytics dashboard showing: fix accuracy trend over time, acceptance/modify/reject rates per language pair, cost per fix trend, estimated time saved, top fix categories, and mode progression per language pair

### Observability & Cost Control

- **FR-SH17:** System can log all Self-healing pipeline events: fix generation (model, tokens, cost, latency), judge evaluation (model, tokens, cost, verdict), trust gateway decision, and user action. All events linked to source finding ID and file ID
- **FR-SH18:** System can enforce Self-healing cost budget per project: configurable monthly cap for AI fix generation + judge verification, **separate from main QA detection budget (FR71)**. Admin dashboard aggregates both budgets for total AI cost visibility. When Self-healing budget reaches 80% ‚Üí warning notification to admin. When budget reached ‚Üí Self-healing pauses, QA detection continues unaffected on its own independent budget

---

## 8. Non-Functional Requirements ‚Äî Self-healing

| NFR-SH# | Requirement | Measurement | Phase |
|---------|------------|-------------|-------|
| NFR-SH1 | Layer 2 quick fix generates in < 3 seconds per finding | API call latency, measured from finding to fix response | Growth |
| NFR-SH2 | Layer 3 deep fix + Judge generates in < 10 seconds per finding | Combined Fix Agent + Judge Agent latency | Growth |
| NFR-SH3 | Shadow Mode adds < 20% overhead to existing QA pipeline processing time | Compare batch processing time with/without Shadow Mode | Growth |
| NFR-SH4 | Fix generation cost < $0.05 per fix (Layer 2) and < $0.15 per fix (Layer 3) | Tracked per fix via FR-SH17 | Growth |
| NFR-SH5 | RAG retrieval adds < 500ms to fix generation | pgvector query latency measurement | Growth |
| NFR-SH6 | Self-healing failure does not block QA pipeline ‚Äî findings always display even if fix generation fails | Test: disconnect fix agent ‚Üí findings still appear | Growth |
| NFR-SH7 | Fix suggestions cached per file version ‚Äî re-opening same file shows previously generated fixes without re-calling AI | Cache key = file hash + finding ID | Growth |

---

## 9. Technical Architecture Notes

### Tech Stack Alignment (No New Infrastructure)

| Component | Existing (Main PRD) | Self-healing Usage |
|-----------|--------------------|--------------------|
| **Vercel AI SDK 6** | AI Layer 2/3 QA analysis | Fix Agent + Judge Agent (generateObject, structured output) |
| **Inngest** | Queue for batch processing | Durable execution for fix pipeline (step.run + step.ai.infer) |
| **Supabase** | Auth, DB, Storage | pgvector for RAG embeddings; fix_suggestions table; shadow_results table |
| **Next.js** | App Router, UI | Fix display components; Self-healing settings pages |
| **Vercel** | Hosting | Same deployment pipeline |

### Database Schema Additions

```
-- New tables for Self-healing (additive, no changes to existing schema)

fix_suggestions
‚îú‚îÄ‚îÄ id (uuid)
‚îú‚îÄ‚îÄ finding_id (FK ‚Üí findings)
‚îú‚îÄ‚îÄ file_id (FK ‚Üí files)
‚îú‚îÄ‚îÄ project_id (FK ‚Üí projects)
‚îú‚îÄ‚îÄ tenant_id
‚îú‚îÄ‚îÄ proposed_fix_text
‚îú‚îÄ‚îÄ original_text
‚îú‚îÄ‚îÄ fix_category (enum: terminology, grammar, semantic, style, tag, formatting)
‚îú‚îÄ‚îÄ confidence_score (0-100)
‚îú‚îÄ‚îÄ judge_verdict (enum: pass, fail, concerns)
‚îú‚îÄ‚îÄ judge_confidence (0-100)
‚îú‚îÄ‚îÄ judge_details (jsonb)
‚îú‚îÄ‚îÄ trust_gateway_decision (enum: auto_apply, suggest, flag_only)
‚îú‚îÄ‚îÄ user_action (enum: accepted, modified, rejected, pending, null)
‚îú‚îÄ‚îÄ user_modified_text (nullable)
‚îú‚îÄ‚îÄ user_rationale (nullable)
‚îú‚îÄ‚îÄ fix_agent_model
‚îú‚îÄ‚îÄ fix_agent_tokens
‚îú‚îÄ‚îÄ fix_agent_cost
‚îú‚îÄ‚îÄ fix_agent_latency_ms
‚îú‚îÄ‚îÄ judge_agent_model
‚îú‚îÄ‚îÄ judge_agent_tokens
‚îú‚îÄ‚îÄ judge_agent_cost
‚îú‚îÄ‚îÄ judge_agent_latency_ms
‚îú‚îÄ‚îÄ rag_context (jsonb ‚Äî glossary matches, similar fixes, surrounding segments)
‚îú‚îÄ‚îÄ is_shadow (boolean ‚Äî true if generated in Shadow Mode)
‚îú‚îÄ‚îÄ created_at
‚îú‚îÄ‚îÄ decided_at
‚îî‚îÄ‚îÄ decided_by (FK ‚Üí users, nullable)

self_healing_config
‚îú‚îÄ‚îÄ id (uuid)
‚îú‚îÄ‚îÄ project_id (FK ‚Üí projects)
‚îú‚îÄ‚îÄ tenant_id
‚îú‚îÄ‚îÄ language_pair
‚îú‚îÄ‚îÄ mode (enum: disabled, shadow, assisted, autonomous)
‚îú‚îÄ‚îÄ shadow_accuracy_threshold (default 85)
‚îú‚îÄ‚îÄ assisted_acceptance_threshold (default 75)
‚îú‚îÄ‚îÄ autonomous_confidence_threshold (default 95)
‚îú‚îÄ‚îÄ auto_revert_threshold (default 5)
‚îú‚îÄ‚îÄ monthly_budget_cap (decimal)
‚îú‚îÄ‚îÄ budget_used_current_month (decimal)
‚îú‚îÄ‚îÄ total_fixes_generated
‚îú‚îÄ‚îÄ total_fixes_accepted
‚îú‚îÄ‚îÄ total_fixes_modified
‚îú‚îÄ‚îÄ total_fixes_rejected
‚îú‚îÄ‚îÄ last_calibration_at
‚îú‚îÄ‚îÄ mode_transition_history (jsonb)
‚îú‚îÄ‚îÄ created_at
‚îî‚îÄ‚îÄ updated_at

fix_embeddings
‚îú‚îÄ‚îÄ id (uuid)
‚îú‚îÄ‚îÄ project_id (FK ‚Üí projects)
‚îú‚îÄ‚îÄ tenant_id
‚îú‚îÄ‚îÄ language_pair
‚îú‚îÄ‚îÄ source_text
‚îú‚îÄ‚îÄ original_target
‚îú‚îÄ‚îÄ corrected_target
‚îú‚îÄ‚îÄ fix_category
‚îú‚îÄ‚îÄ embedding (vector(1536))
‚îú‚îÄ‚îÄ metadata (jsonb)
‚îú‚îÄ‚îÄ created_at
‚îî‚îÄ‚îÄ source_fix_id (FK ‚Üí fix_suggestions)
```

### Inngest Pipeline Flow

```typescript
// Conceptual flow ‚Äî not implementation code

inngest.createFunction("self-healing-pipeline", async ({ step }) => {
  // Step 1: Check if Self-healing is enabled for this language pair
  const config = await step.run("check-config", () => getConfig(projectId, langPair));
  if (config.mode === "disabled") return;

  // Step 2: Retrieve RAG context
  const ragContext = await step.run("rag-retrieval", () =>
    retrieveContext(finding, projectId, langPair)
  );

  // Step 3: Generate fix (Layer 2 or 3 based on complexity)
  const fix = await step.ai.infer("generate-fix", {
    model: selectModel(finding.complexity),
    prompt: buildFixPrompt(finding, ragContext),
    schema: fixOutputSchema, // Zod schema for constrained output
  });

  // Step 4: Judge Agent verification
  const verdict = await step.ai.infer("judge-fix", {
    model: judgeModel,
    prompt: buildJudgePrompt(finding, fix, ragContext),
    schema: judgeOutputSchema,
  });

  // Step 5: Trust Gateway decision
  const decision = await step.run("trust-gateway", () =>
    routeFix(fix, verdict, config)
  );

  // Step 6: Store result
  await step.run("store-fix", () =>
    storeFix(fix, verdict, decision, config.mode === "shadow")
  );
});
```

---

## 10. Implementation Roadmap

### Phase 0: Foundation (Growth ‚Äî Month 3, schema in MVP)

> FR73-FR75 in main PRD (Growth scope). Schema design included in MVP Month 1-2.

- [ ] `fix_suggestions` table schema (with `is_shadow` column ready) ‚Äî **MVP: schema only**
- [ ] `self_healing_config` table schema (mode defaults to "disabled") ‚Äî **MVP: schema only**
- [ ] Rule-based auto-fix implementation ‚Äî **Growth**
- [ ] Auto-fix preview UI component ‚Äî **Growth**
- [ ] Auto-fix acceptance tracking ‚Äî **Growth**

### Phase 1: Shadow Mode (Growth ‚Äî Month 3-4)

- [ ] Fix Agent implementation (Vercel AI SDK generateObject)
- [ ] Judge Agent implementation (separate model/prompt)
- [ ] Inngest pipeline for fix generation
- [ ] RAG setup: pgvector extension + `fix_embeddings` table
- [ ] Shadow Mode: generate fixes silently, store in DB
- [ ] Internal accuracy dashboard (compare AI fix vs reviewer's correction)
- [ ] Per-language pair confidence tracking
- [ ] Shadow Mode admin settings UI

### Phase 2: Assisted Mode (Growth ‚Äî Month 5-6)

- [ ] Fix display UI alongside findings (üíä icon + panel)
- [ ] Accept/Modify/Reject actions with feedback capture
- [ ] Bulk accept for high-confidence fixes
- [ ] Before/after preview component
- [ ] Feedback loop: accepted fixes ‚Üí RAG embeddings
- [ ] Confidence threshold auto-recalibration
- [ ] Mode transition logic (Shadow ‚Üí Assisted)
- [ ] Self-healing analytics dashboard
- [ ] Cost tracking and budget enforcement

### Phase 3: Autonomous Mode (Vision ‚Äî Month 8+)

- [ ] Trust Gateway auto-apply logic
- [ ] Auto-applied fix display with revert capability
- [ ] Mode transition logic (Assisted ‚Üí Autonomous)
- [ ] Auto-revert safety circuit (revert rate > 5% ‚Üí back to Assisted)
- [ ] Advanced RAG: fine-tuning preparation with accumulated data
- [ ] Cross-project learning (anonymized fix patterns)

---

## 11. Cost Projections

### Per-Fix Cost Breakdown

| Component | Layer 2 (Quick) | Layer 3 (Deep) |
|-----------|:---------------:|:--------------:|
| Fix Agent | ~$0.01-0.02 | ~$0.05-0.08 |
| Judge Agent | ~$0.005-0.01 | ~$0.02-0.04 |
| RAG retrieval | ~$0.001 | ~$0.001 |
| **Total per fix** | **~$0.02-0.03** | **~$0.07-0.12** |

### Monthly Cost Estimate (Assisted Mode)

| Scenario | Files/month | Findings/file | Fixes/month | Monthly Cost |
|----------|:-----------:|:-------------:|:-----------:|:------------:|
| Small team (Mona's) | 200 | 15 | 3,000 | $60-90 |
| Medium team | 500 | 15 | 7,500 | $150-225 |
| Large team | 2,000 | 15 | 30,000 | $600-900 |

### Cost Optimization Strategies

1. **Prompt caching** ‚Äî Vercel AI SDK cache: up to 90% token cost reduction for repeated patterns
2. **Model routing** ‚Äî Use cheaper model for Layer 2, premium for Layer 3 only
3. **RAG context reduction** ‚Äî Focused retrieval reduces input tokens by ~70%
4. **Fix caching** ‚Äî Same finding pattern ‚Üí retrieve cached fix (no new API call)
5. **Batch optimization** ‚Äî Group similar findings for single API call

---

## 12. Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|:-----------:|:------:|-----------|
| AI fix introduces new errors | Medium | High | Judge Agent + rule-based post-validation |
| Users lose trust in QA findings due to bad fixes | Low | Critical | Fixes are separate from detection ‚Äî bad fix ‚â† bad detection |
| Fix costs exceed budget | Medium | Medium | Per-project budget cap (FR-SH18) + cost alerts |
| Shadow Mode delays Growth features | Low | Medium | Shadow Mode runs in background ‚Äî no UI work until Phase 2 |
| Language pair accuracy varies significantly | High | Medium | Per-language pair thresholds + separate mode transitions |
| RAG embedding quality degrades over time | Low | Medium | Periodic reindexing + embedding model version tracking |
| Competitor launches similar feature | Medium | Medium | First-mover advantage + data moat from feedback loop |

---

## 13. Open Questions

1. **Fix Agent model selection:** Start with Claude Sonnet 4.5 (balance cost/quality) or Haiku 4.5 (cost-optimized)? ‚Üí Decide during Shadow Mode based on accuracy data
2. **Judge Agent model:** Same model as Fix Agent or different? ‚Üí Research suggests different model reduces bias
3. **RAG embedding model:** text-embedding-3-small vs text-embedding-3-large? ‚Üí Start small, upgrade if retrieval quality insufficient
4. **Cross-project learning:** Can anonymized fix patterns from one project improve another? ‚Üí Defer to Vision phase, privacy review required
5. **Fine-tuning timeline:** When is accumulated data sufficient for model fine-tuning? ‚Üí Target 10,000+ accepted fixes per language pair

---

*This PRD is a living document. It will be updated as Shadow Mode data reveals accuracy patterns and user feedback shapes the Self-healing experience.*

*Cross-reference: [Main PRD](prd.md) | [Self-healing Translation Research](research/technical-ai-llm-self-healing-translation-research-2026-02-14.md)*
