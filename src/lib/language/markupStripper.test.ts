// üî¥ TDD RED PHASE ‚Äî tests will fail until markupStripper.ts is implemented
// Story 1.5: Glossary Matching Engine for No-space Languages

import { describe, expect, it } from 'vitest'

import { MAX_SEGMENTER_CHUNK, chunkText, stripMarkup } from './markupStripper'

describe('stripMarkup', () => {
  it('should replace HTML bold tags with equal-length spaces', () => {
    const input = '<b>‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°</b>'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped).not.toContain('<b>')
    expect(stripped).not.toContain('</b>')
  })

  it('should preserve character positions ‚Äî tag chars replaced with spaces', () => {
    const input = '<x id="1"/>‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    // ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° must start at same offset as original
    const tagLen = '<x id="1"/>'.length
    expect(stripped.slice(tagLen)).toBe('‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°')
  })

  it('should replace {0} placeholder with spaces', () => {
    const input = '{0} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped.slice(0, 3)).toBe('   ')
    expect(stripped.slice(3)).toBe(' ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£')
  })

  it('should replace {name} placeholder with spaces', () => {
    const input = '{name} ‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped.slice(0, 6)).toBe('      ')
  })

  it('should replace %s format string with spaces', () => {
    const input = '%s ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped.slice(0, 2)).toBe('  ')
  })

  it('should replace %1$s format string with spaces', () => {
    const input = '%1$s ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped.slice(0, 4)).toBe('    ')
  })

  it('should handle empty string without error', () => {
    expect(stripMarkup('')).toBe('')
  })

  it('should return unchanged text when no markup present', () => {
    const text = '‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏•‡πâ‡∏ß‡∏ô'
    expect(stripMarkup(text)).toBe(text)
  })

  it('should handle XLIFF g-tag wrapping', () => {
    const input = '<g id="1">‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</g>'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    // "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç" is preserved inside
    expect(stripped).toContain('‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç')
  })

  it('should handle multiple markup patterns in one string', () => {
    const input = '<b>{0}</b> ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'
    const stripped = stripMarkup(input)
    expect(stripped.length).toBe(input.length)
    expect(stripped).toContain('‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£')
  })
})

describe('chunkText', () => {
  it('should return single chunk for text shorter than MAX_SEGMENTER_CHUNK', () => {
    const text = '‡∏Å'.repeat(100)
    const chunks = chunkText(text)
    expect(chunks).toHaveLength(1)
    expect(chunks[0]).toEqual({ chunk: text, offset: 0 })
  })

  it('should return single chunk for text exactly MAX_SEGMENTER_CHUNK chars', () => {
    const text = '‡∏Å'.repeat(MAX_SEGMENTER_CHUNK)
    const chunks = chunkText(text)
    expect(chunks).toHaveLength(1)
    expect(chunks[0]?.offset).toBe(0)
    expect(chunks[0]?.chunk.length).toBe(MAX_SEGMENTER_CHUNK)
  })

  it('should return 2 chunks for text MAX_SEGMENTER_CHUNK + 1 chars', () => {
    const text = '‡∏Å'.repeat(MAX_SEGMENTER_CHUNK + 1)
    const chunks = chunkText(text)
    expect(chunks).toHaveLength(2)
    expect(chunks[0]?.offset).toBe(0)
    expect(chunks[1]?.offset).toBe(MAX_SEGMENTER_CHUNK)
    expect(chunks[1]?.chunk.length).toBe(1)
  })

  it('should return 3 chunks for text of 2√óMAX + 1 chars with correct offsets', () => {
    const text = '‡∏Å'.repeat(MAX_SEGMENTER_CHUNK * 2 + 1)
    const chunks = chunkText(text)
    expect(chunks).toHaveLength(3)
    expect(chunks[0]?.offset).toBe(0)
    expect(chunks[1]?.offset).toBe(MAX_SEGMENTER_CHUNK)
    expect(chunks[2]?.offset).toBe(MAX_SEGMENTER_CHUNK * 2)
  })

  it('should reconstruct original text by joining all chunks', () => {
    const text = '‡∏Å‡∏Ç‡∏Ñ'.repeat(MAX_SEGMENTER_CHUNK + 100)
    const chunks = chunkText(text)
    const reconstructed = chunks.map((c) => c.chunk).join('')
    expect(reconstructed).toBe(text)
  })
})

describe('MAX_SEGMENTER_CHUNK', () => {
  it('should be 30000', () => {
    expect(MAX_SEGMENTER_CHUNK).toBe(30_000)
  })
})
